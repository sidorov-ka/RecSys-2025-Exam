# Ответы на экзамен по RecSys 2025 (вопросы 1–10)

## 1. Формальная постановка задачи

### Персональные рекомендации
- Пользователи: \( \mathcal{U} = \{u_1, ..., u_n\} \)
- Айтемы: \( \mathcal{I} = \{i_1, ..., i_m\} \)
- Матрица взаимодействий: \( R \in \mathbb{R}^{n \times m} \), где \( R_{ui} \) — факт взаимодействия
- Цель: построить функцию \( \hat{r}_{ui} = f(u, i) \), предсказывающую интерес пользователя к айтему, и получить Top-N:
  \[
  \text{TopN}(u) = \text{argsort}_i(f(u, i))[:N]
  \]

### Ранжирование поисковой выдачи
- Запросы: \( q \in \mathcal{Q} \), документы: \( d \in \mathcal{D} \)
- Цель: ранжировать документы по релевантности \( f(q, d) \)

**Общее:** обе задачи сводятся к ранжированию объектов в заданном контексте (пользователь или запрос).

---

## 2. Типы функций ранжирования

| Тип       | Описание                       | Пример         | Учитывает порядок |
|-----------|--------------------------------|----------------|-------------------|
| Pointwise | Релевантность по одному айтему | MSE, CrossEntropy | ❌                |
| Pairwise  | Сравнение двух айтемов         | BPR, RankNet   | ⚠ Частично        |
| Listwise  | Ранжирование всего списка      | NDCG, ListNet  | ✅                |

### Примеры:
- **Pointwise**: \( \text{MSE}(y, \hat{y}) = \frac{1}{n} \sum (y_i - \hat{y}_i)^2 \)
- **Pairwise (BPR)**: \( -\log \sigma(\hat{r}_{ui^+} - \hat{r}_{ui^-}) \)
- **Listwise**: LambdaRank, оптимизация NDCG

---

## 3. Разница между BPR и WARP

### BPR:
- Работает на триплетах (u, i⁺, i⁻)
- Loss: \( -\log \sigma(\hat{r}_{ui^+} - \hat{r}_{ui^-}) \)
- Быстрый, хорошо работает с implicit feedback

### WARP:
- Делает sampling до нарушения условия \( \hat{r}_{ui^-} > \hat{r}_{ui^+} \)
- Наказывает за неправильный порядок в топе
- Loss зависит от ранга: \( \sum_{k=1}^K \frac{1}{k} \cdot \max(0, 1 + \hat{r}_{ui^-} - \hat{r}_{ui^+}) \)

### Гиперпараметры:
- `factors`: 64–128
- `learning_rate`: 0.001–0.05
- `regularization`: 0.01–0.1
- `num_negatives` (для WARP): 5–10

---

### 4. Метрики для оценки качества ранжирования

#### Precision@k
Показывает, какую долю из top-k рекомендованных айтемов пользователь действительно считает релевантными.
\[
\text{Precision@k} = \frac{|\{ \text{релевантные айтемы в топ-k} \}|}{k}
\]

#### Recall@k
Показывает, какую долю от всех релевантных айтемов мы угадали.
\[
\text{Recall@k} = \frac{|\{ \text{релевантные в топ-k} \}|}{|\{ \text{все релевантные} \}|}
\]

#### MAP@k (Mean Average Precision)
Средний precision по всем релевантным позициям, усреднённый по пользователям:
\[
\text{MAP@k} = \frac{1}{|U|} \sum_{u \in U} \left( \frac{1}{|Rel_u|} \sum_{i \in \text{top-k}} P(i) \cdot rel(i) \right)
\]

#### NDCG@k
Учитывает не только наличие релевантных айтемов, но и их позицию:
\[
\text{DCG@k} = \sum_{i=1}^{k} \frac{2^{rel_i} - 1}{\log_2(i + 1)}, \quad
\text{NDCG@k} = \frac{DCG@k}{IDCG@k}
\]

---

### 5. Разбор метрики NDCG@k

- **Логарифм в знаменателе**: снижает вклад айтемов, стоящих ниже в списке — модель фокусируется на верхе.
- **Показательная функция \( 2^{rel} - 1 \)**: усиливает вклад релевантных айтемов с большим рейтингом (например, 3 лучше чем 2 не просто в 1.5 раза, а в 4 раза).
- **Формула считается для каждого пользователя**, а затем усредняется по всем (macro average).
- **Релевантность может быть не бинарной**, т.е. не обязательно 0/1 — можно использовать шкалу (например, 0–3).

---

### 6. Может ли рост оффлайн метрик ухудшить онлайн?

Да. Некоторые причины:
- **Feedback loop**: пользователь видит только то, что рекомендует система → данные искажаются.
- **Distribution shift**: данные для оффлайн оценки устарели, а поведение пользователей изменилось.
- **Недостаточные оффлайн метрики**: Precision/NDCG не учитывают diversity, novelty, unexpectedness.

#### Пример:
Оффлайн модель увеличила Precision@10, но все рекомендации стали одними и теми же → пользовательский CTR в онлайне упал.

---

### 7. Что такое матрица интеракций?

Матрица \( R \in \mathbb{R}^{n \times m} \), где:
- \( n \) — количество пользователей
- \( m \) — количество айтемов
- \( R_{ui} \) — взаимодействие пользователя \( u \) с айтемом \( i \)

Может быть:
- **Dense** (например, рейтинги 1–5)
- **Sparse** (0/1 — клик был или нет)

Часто хранится в формате CSR/COO.

---

### 8. Разница между implicit и explicit feedback

| Тип       | Примеры                        | Характеристика                       |
|-----------|--------------------------------|--------------------------------------|
| Explicit  | Оценки (звезды, баллы)         | Явное выражение предпочтения         |
| Implicit  | Клики, просмотры, покупки      | Неявное поведение, требует интерпретации |

- Implicit данные легче собрать, но сложнее интерпретировать.
- Explicit данные — точнее, но их меньше.

---

### 9. Как задать взаимодействия по кликам и просмотрам?

Варианты:
- **Бинаризация**: если просмотр был → \( R_{ui} = 1 \)
- **Взвешивание событий**: просмотр = 1, клик = 2, покупка = 3
- **Decay по времени**: старые взаимодействия менее важны:
  \[
  \text{weight}_{ui} = \exp\left(-\lambda \cdot \Delta t_{ui} \right)
  \]

Также можно учитывать длительность сессии, позицию в ленте и др.

---

### 10. Пример рекомендаций без обучения модели

#### Item-based KNN:
- Считаем матрицу сходства между айтемами (косинусное, Jaccard и др.)
- Для каждого айтема находим похожие
- Рекомендуем пользователю айтемы, похожие на те, с которыми он уже взаимодействовал

#### User-based KNN:
- Находим пользователей с похожим поведением
- Рекомендуем айтемы, которые нравятся «соседям»

**Плюсы**: простота, интерпретируемость  
**Минусы**: плохо масштабируется, не учитывает латентные предпочтения
---

### 11. Что такое матричное разложение и чем оно отличается от коллаборативной фильтрации?

**Матричное разложение (Matrix Factorization)** — это метод аппроксимации матрицы взаимодействий \( R \in \mathbb{R}^{n \times m} \) с помощью двух низкоразмерных матриц:

\[
R \approx U \cdot V^\top, \quad \hat{r}_{ui} = \langle u_u, v_i \rangle
\]

Где:
- \(U \in \mathbb{R}^{n \times d}\) — эмбеддинги пользователей
- \(V \in \mathbb{R}^{m \times d}\) — эмбеддинги айтемов

**Отличие от коллаборативной фильтрации (CF)**:
- **UserKNN/ItemKNN** ищут похожих пользователей/айтемов с использованием метрик сходства
- **MF** обучает скрытые представления, извлекая латентные паттерны из данных

---

### 12. Почему матричное разложение не рекомендует уже просмотренные айтемы?

MF предсказывает интерес \( \hat{r}_{ui} \) для всех айтемов, в том числе тех, с которыми пользователь уже взаимодействовал. Чтобы избежать рекомендаций повторно:
- **После получения топ-N** система фильтрует уже известные айтемы
- Это делается **на этапе инференса**, а не во время обучения

MF сам по себе не знает о повторениях — это задача постобработки.

---

### 13. Способы разбиения данных для оффлайн-оценки

1. **Random Split** — случайное разбиение событий
2. **Leave-One-Out** — последнее взаимодействие → test
3. **Time-based Split** — разбиение по времени (train до определённого timestamp)
4. **Session-based Split** — разбивает по сессиям пользователей

**Лучшее разбиение** — **Time-based split**, так как оно ближе к реалистичному сценарию с онлайн-оценкой.

---

### 14. Что такое Leave-One-Out?

Метод разбиения для оффлайн-оценки:

- Для каждого пользователя \( u \):
  - Последнее взаимодействие \( i_t \) → в тест
  - Остальные \( i_1, ..., i_{t-1} \) → в train

**Пример**:
\[
\text{train}(u) = \{i_1, i_2, i_3\}, \quad \text{test}(u) = \{i_4\}
\]

Этот подход часто используется в implicit задачах и позволяет симулировать «следующее действие».

---

### 15. Как работает двухуровневая архитектура рекомендательной системы?

Архитектура состоит из двух фаз:

#### 1. **Candidate Generation** (первый уровень)
- Быстрые алгоритмы: ALS, itemKNN, LightGCN
- Генерируют топ-K кандидатов (обычно K = 100–1000)

#### 2. **Reranking** (второй уровень)
- Сложная модель (GBM, нейросеть) пересортировывает кандидатов
- Используются признаки: время, история, контекст, признаки айтема/пользователя

**Формально**:
\[
\text{TopN}(u) = \text{argsort}_i(f_\text{ranker}(u, i, \text{features}))
\]

---

### 16. Почему можно использовать градиентный бустинг вместо нейросети?

**Градиентный бустинг (GBDT/LightGBM/XGBoost)**:
- Работает лучше с табличными данными
- Требует меньше гиперпараметров
- Быстро обучается и интерпретируем

**Нейросети**:
- Сложнее в обучении
- Требуют больше данных
- Лучше работают с мультимодальными или последовательными входами

**Формула**: градиентный бустинг минимизирует loss с помощью ансамбля деревьев
\[
\hat{y} = \sum_{t=1}^T f_t(x), \quad f_t \in \mathcal{F}
\]

---

### 17. Когда нужно и не нужно исключать уже взаимодействовавшие айтемы?

#### Исключать:
- При генерации рекомендаций «нового» контента
- При оценке оффлайн-метрик (иначе метрики будут переоценены)
- В personalized ленте/магазине

#### Не исключать:
- Повторные покупки
- Продолжение взаимодействия (серии, музыка, еда)

**Важно**: поведение зависит от типа домена. Например, Spotify не исключает треки, которые пользователь слушал вчера.
---

### 18. Что такое гибридная рекомендательная система?

Гибридная система — это модель, которая объединяет разные подходы к рекомендациям:

#### Виды гибридов:
- **Content-based + CF**: объединяет похожесть по признакам и по интеракциям
- **Rule-based + ML**: логика + модель
- **Ensemble**: объединение выходов моделей (blending/stacking)
- **Switching**: выбираем модель в зависимости от контекста

#### Пример:
Рекомендовать фильмы с учетом:
- жанра (контент)
- лайков пользователей (CF)
- популярности (правила)

**Цель** — устранить слабые стороны отдельных методов и повысить качество рекомендаций.

---

### 19. Какие рекомендательные системы не зависят от домена?

Системы, не зависящие от структуры айтемов или предметной области:

| Тип                 | Почему независим от домена                            |
|---------------------|--------------------------------------------------------|
| **Content-based**   | Использует признаки айтемов, а не интеракции          |
| **Knowledge-based** | Использует внешние правила или граф знаний            |
| **Rule-based**      | Предопределенные сценарии: "если пользователь X, то Y"|

**Пример**: рекомендация курса на основании описания, а не истории поведения.

---

### 20. Что такое popular bias?

**Popular bias** — смещение рекомендаций в сторону часто взаимодействуемых (популярных) айтемов.

#### Причины:
- Модель учится на интеракциях, где преобладают популярные объекты
- Имплицитные данные (просмотры/клики) не равны интересу

#### Последствия:
- Упрощённые модели рекомендуют «популярное всем»
- Теряется personalization, novelty

#### Методы борьбы:
- Penalize popular items (inverse propensity)
- Reranking с diversity-aware функциями
- Re-weighting примеров

---

### 21. Что такое cold start и как его решать?

**Cold start** — ситуация, когда система не может дать рекомендацию из-за нехватки данных:

#### Виды:
- **Новый пользователь**: нет истории
- **Новый айтем**: никто не взаимодействовал
- **Новый домен**: перенос модели

#### Решения:
- **Контентные признаки**: эмбеддинги, описание, категории
- **Методы мета-обучения / transfer learning**
- **Popularity-based fallback**
- **Онбординг**: опросы и т.п.

---

### 22. Метрики diversity, novelty, coverage, serendipity

#### Diversity:
Показывает различие между рекомендованными айтемами:
\[
\text{Diversity@k} = \frac{2}{k(k-1)} \sum_{i<j} (1 - \text{sim}(i, j))
\]

#### Novelty:
Мера неожиданности, обратная популярности:
\[
\text{Novelty}(i) = -\log p(i)
\]

#### Coverage:
Процент разных айтемов, попавших в рекомендации:
\[
\text{Coverage} = \frac{|\text{recommended items}|}{|\text{all items}|}
\]

#### Serendipity:
Мера удивительности и полезности:
\[
\text{Serendipity} = \text{unexpected} \cap \text{relevant}
\]

---

### 23. Что такое feedback loop?

**Feedback loop** — система искажает собственные данные:

1. Система рекомендует определённый контент
2. Пользователь видит только его → взаимодействует
3. Модель усиливает прежний паттерн

#### Пример:
- Модель рекомендует только популярное → собирает больше клик-беков → ещё больше популярного

#### Методы борьбы:
- A/B тесты
- Эксплоративная подмешка (exploration-exploitation)
- Counterfactual learning

---

### 24. Что такое information bubble?

**Информационный пузырь** — узкий круг интересов, в который модель "запирает" пользователя.

#### Причины:
- Алгоритм рекомендует только то, что уже нравится
- Нет механизма расширения интересов

#### Последствия:
- Скучные, однотипные рекомендации
- Пользователь не видит разнообразие

#### Решения:
- Введение diversity
- Hybrid + randomization
- Учет long-tail контента
---

### 25. В чем разница между оффлайн и онлайн метриками?

| Метрика        | Где считается             | Примеры                     | Особенности                      |
|----------------|----------------------------|------------------------------|-----------------------------------|
| **Оффлайн**    | На отложенной выборке      | NDCG@k, MAP@k, Recall@k      | Быстрая, повторяемая, но приближенная |
| **Онлайн**     | В реальном времени (A/B)   | CTR, CVR, Retention, WatchTime | Реальные реакции пользователей     |

- **Разрыв возможен**: модель может быть хорошей оффлайн, но плохой онлайн из-за:
  - feedback loop
  - distribution shift
  - отсутствия факторов, доступных в проде (например, latency)

---

### 26. Почему не все айтемы доступны пользователю при рекомендации?

Причины:
- **Ограничения бизнес-логики** (товар недоступен, устарел, нет в наличии)
- **Локальные особенности**: языковые, региональные
- **Фильтрации платформы**: возраст, подписка
- **Персональные фильтры**: запрет контента, блокировки

#### Следствие:
- При генерации кандидатов важно учитывать фильтрацию допустимых айтемов.

---

### 27. Что такое монотонные ограничения в модели ранжирования?

**Монотонные ограничения (monotonic constraints)** — требование, чтобы при увеличении значения признака не ухудшалось предсказание.

#### Пример:
Если признак "рейтинг товара" выше, то score не должен падать:
\[
x_1 > x_2 \Rightarrow f(x_1) \ge f(x_2)
\]

#### Используется в:
- GBDT (XGBoost, LightGBM): параметр `monotone_constraints`
- Нейросетях через регуляризацию или архитектуру

**Зачем**:
- Повышает интерпретируемость
- Встраивает доменные знания

---

### 28. Как интерпретировать рекомендации через SHAP?

**SHAP (SHapley Additive exPlanations)** — метод интерпретации вкладов признаков:
- Основан на теории игр
- Каждому признаку присваивается вклад в предсказание

#### Применение:
- Для ранкеров второго уровня (например, LightGBM)
- Объяснение, почему рекомендован айтем:
  > «Рекомендовано, потому что вы часто выбираете бренды X, и цена ниже средней»

#### Формально:
\[
f(x) = \phi_0 + \sum_{i=1}^{n} \phi_i
\]
где \(\phi_i\) — вклад i-го признака.

---

### 29. Может ли модель второго уровня учитывать сезонность?

Да, через добавление соответствующих признаков:
- **Время суток** (hour, weekday)
- **Месяц, квартал**
- **Периоды активности пользователя**
- **Связь с календарём событий (праздники, акции)**

#### Примеры признаков:
- `hour_bin = [0-6], [6-12], ...`
- `is_weekend`, `is_holiday`

Модель (например, GBDT или MLP) может автоматически учитывать эти зависимости.

---

### 30. Что такое switching в гибридной системе?

**Switching** — стратегия, при которой система **переключается** между несколькими моделями в зависимости от условий.

#### Примеры:
- Для новых пользователей → content-based
- Для активных → CF
- Если не удалось сгенерировать топ-N → популярные айтемы

**Преимущества**:
- Простота реализации
- Устойчивость к cold start

---

### 31. Как работает implicit ALS и как его расширить?

#### Implicit ALS (Alternating Least Squares):
- Матричное разложение для неявных (implicit) данных
- Использует взвешенную функцию ошибки:

\[
\min_{X,Y} \sum_{u,i} c_{ui} (p_{ui} - x_u^T y_i)^2 + \lambda (\|x_u\|^2 + \|y_i\|^2)
\]
где:
- \( p_{ui} = 1 \) если есть взаимодействие, иначе 0
- \( c_{ui} = 1 + \alpha \cdot r_{ui} \) — confidence

#### Достоинства:
- Быстрое обучение (особенно с CPU/parallel)
- Устойчив к sparsity

#### Недостатки:
- Нет последовательности/контекста
- Трудно учитывать признаки

#### Как добавить признаки:
- Слияние внешних эмбеддингов в \( X \) и \( Y \)
- Factorization Machines
- Feature-aware sampling и LightFM

#### Как учесть время:
- Сэмплирование по decay-функции
- Матрицы по временам (утро, вечер)
- Взвешивание интеракций по давности

#### Объяснение:
- Объяснение в ALS возможно через похожесть: "Потому что похож на то, что вы смотрели"
- Можно интерпретировать через близость эмбеддингов

---

### 32. Как работает userKNN/itemKNN? Достоинства и недостатки

#### itemKNN:
- Рекомендации строятся на похожих айтемах:
  \[
  \hat{r}_{ui} = \sum_{j \in N(i)} \text{sim}(i, j) \cdot r_{uj}
  \]
  Где \( N(i) \) — k ближайших айтемов к \( i \)

#### userKNN:
- Рекомендации на основе похожих пользователей:
  \[
  \hat{r}_{ui} = \sum_{v \in N(u)} \text{sim}(u, v) \cdot r_{vi}
  \]

#### Метрики похожести:
- Cosine, Pearson, Jaccard

#### Плюсы:
- Простота, интерпретируемость
- Нет обучения — "memory-based"

#### Минусы:
- Медленно при большом числе пользователей/айтемов
- Плохо масштабируется

---

### 33. Как устроена модель EASE и чем отличается от SLIM?

#### EASE (Embarrassingly Shallow AutoEncoder):
- Линейная модель для рекомендаций на основе регрессии:
  \[
  \hat{r}_u = X_u \cdot B
  \]
  где \( B \) — матрица параметров, решается как:
  \[
  B = (X^T X + \lambda I)^{-1} X^T X
  \]

- Симметричность и регуляризация делают EASE очень эффективной

#### SLIM (Sparse Linear Methods):
- То же самое, но с L1-регуляризацией:
  \[
  \min_B \|X - XB\|^2 + \lambda_1 \|B\|_1 + \lambda_2 \|B\|_2
  \]
- Медленнее, но даёт разреженные веса

#### Отличия:

| Метод | Регуляризация | Быстрота | Интерпретируемость |
|-------|----------------|-----------|--------------------|
| EASE  | L2             | Очень быстрая | Да               |
| SLIM  | L1 + L2        | Медленная     | Да               |

---

### 34. Как работает LightFM? Достоинства и недостатки

**LightFM** — факторизационная модель, объединяющая CF и контентные признаки.

\[
\hat{r}_{ui} = \langle x_u, y_i \rangle
\]
где:
- \( x_u \) = эмбеддинг пользователя (в т.ч. от признаков)
- \( y_i \) = эмбеддинг айтема

#### Особенности:
- Использует признаки (теги, категории)
- Поддерживает разные loss: BPR, WARP, logistic

#### Плюсы:
- Подходит для cold start
- Быстрая и гибкая
- Поддержка scikit-learn стиля

#### Минусы:
- Ограничена по масштабируемости
- Нет учёта последовательности

---

### 35. Как работает SASRec? Достоинства и недостатки

**SASRec (Self-Attentive Sequential Recommendation)** — последовательная модель на основе Transformer.

#### Архитектура:
- Вход: последовательность айтемов \([i_1, i_2, ..., i_t]\)
- Каждое \( i_t \) проходит через:
  - эмбеддинг
  - позиционный эмбеддинг
  - self-attention блоки

\[
\hat{r}_{ui} = f_{\text{attn}}(i_1, ..., i_t, i)
\]

#### Плюсы:
- Учитывает порядок и дистанцию
- Обучается end-to-end
- Подходит для next-item prediction

#### Минусы:
- Тяжёлый при длинных последовательностях
- Неустойчив к sparsity
- Требует GPU

---

### 36. Как работает BERT4Rec? Достоинства и недостатки

**BERT4Rec** — последовательная модель, основанная на bidirectional Transformer (BERT), обучается с маскированием.

#### Отличие от SASRec:
- SASRec — унидирекционный (предсказывает следующее)
- BERT4Rec — бидирекционный (восстанавливает маски)

#### Обучение:
- Маскируется часть айтемов
- Цель: восстановить их с помощью внимания

\[
\mathcal{L} = \sum_{i \in \text{masked}} -\log P(i | \text{context})
\]

#### Плюсы:
- Учит глобальный контекст
- Работает как автокодировщик

#### Минусы:
- Сложнее в инференсе
- Тяжелее, чем SASRec
- Не может использоваться напрямую для autoregressive задач

---

### 37. Отличия между BERT4Rec и SASRec

| Характеристика        | SASRec                          | BERT4Rec                          |
|------------------------|----------------------------------|------------------------------------|
| Направленность        | Упорядоченный (left-to-right)   | Бидирекциональный                 |
| Обучение              | Next item prediction             | Masked item prediction            |
| Loss                  | BPR / Cross-Entropy              | MLM (Masked LM)                  |
| Скорость инференса    | Быстрее                          | Медленнее                         |
| Учёт порядка          | Есть                             | Есть, но без авто-регрессии       |

---

### 38. Как работает LightGCN? Достоинства и недостатки

**LightGCN** — упрощённая версия GCN для коллаборативной фильтрации.

#### Основная идея:
- Представить интеракции как граф \( G = (U \cup I, E) \)
- Эмбеддинги обновляются по соседям:

\[
e_u^{(k+1)} = \sum_{i \in \mathcal{N}(u)} \frac{1}{\sqrt{|\mathcal{N}(u)||\mathcal{N}(i)|}} e_i^{(k)}
\]

- Итоговая эмбеддинговая сумма:
\[
e_u = \sum_{k=0}^K \alpha_k e_u^{(k)}
\]

#### Плюсы:
- Учитывает структуру графа
- Простая и масштабируемая

#### Минусы:
- Не учитывает время и контент
- Статичная архитектура (всё эмбеддинги фиксированы)
---

### 39. Как из обученного вариационного автоэнкодера получить рекомендации?

**VAE** (Variational AutoEncoder) используется для генерации скрытых представлений пользователя:
- Вход: бинарный вектор взаимодействий \( x_u \)
- Кодер: \(\mu_u, \sigma_u = f_{\text{enc}}(x_u)\)
- Сэмплируется латентный вектор: \( z_u \sim \mathcal{N}(\mu_u, \sigma_u^2) \)
- Декодер: предсказывает вероятность взаимодействия с каждым айтемом:
  \[
  \hat{r}_u = f_{\text{dec}}(z_u)
  \]

#### Получение рекомендаций:
1. На инференсе берём \(\mu_u\) как эмбеддинг
2. Считаем \(\hat{r}_u = f_{\text{dec}}(\mu_u)\)
3. Выбираем топ-N по \(\hat{r}_u\)

---

### 40. Как работает MultiVAE? Чем отличается от MultiDAE?

**MultiVAE** — вероятностная модель для рекомендаций, обучаемая с использованием регуляризации на латентное пространство.

\[
\mathcal{L} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - \beta \cdot \text{KL}(q(z|x) \| p(z))
\]

**MultiDAE** — тот же автоэнкодер, но без вероятностной составляющей:
- Нет sampling и KL-дивергенции
- Обучается просто как реконструкция

#### Сравнение:

| Характеристика  | MultiVAE                    | MultiDAE                    |
|------------------|------------------------------|------------------------------|
| Латентное пространство | Стохастическое (\( z \sim N(\mu, \sigma) \)) | Детерминированное |
| Регуляризация   | Да (KL)                      | Нет                         |
| Подходит для cold-start | Лучше                    | Хуже                        |

---

### 41. Как можно делать объяснения рекомендаций?

Способы объяснения:

#### 1. **Интринсивные (встроенные)**:
- KNN: "Потому что вы смотрели X, похожий на Y"
- Decision Trees: можно проследить путь
- GNN attention / веса эмбеддингов

#### 2. **Агностические (post-hoc)**:
- SHAP: вклад признаков
- LIME: локальная аппроксимация модели
- Attention weights (в SASRec/BERT4Rec)

#### 3. **Темпоральные**:
- Показывать прошлую последовательность, которая привела к выбору

---

### 42. Что такое uplift-рекомендации? Примеры моделей

**Uplift** — модель предсказывает **разницу эффекта от рекомендации**:
\[
\text{Uplift} = P(Y=1 | T=1, X) - P(Y=1 | T=0, X)
\]

Где:
- \(T=1\) — если был рекомендован айтем
- \(Y\) — целевое действие (клик, покупка)

#### Применения:
- Оценка эффекта показа
- Оптимизация показов (только если uplift положителен)

#### Модели:
- Uplift Random Forest
- Causal Forest
- Meta-learners (T-learner, X-learner)
- DeepUplift / GAN-based подходы

---

### 43. Примеры multi-task задач и подходящая архитектура

#### Примеры задач:
- Предсказать одновременно:
  - Клик (CTR)
  - Покупку (CVR)
  - Отток (churn)
  - Лайк + комментарий

#### Подходящие архитектуры:
- **Shared-bottom**: общие слои + task-specific heads
- **MMoE** (Multi-gate Mixture-of-Experts)
- **PLE** (Progressive Layered Extraction)

#### Зачем:
- Повышает сэмпловую эффективность
- Учит представления общего вида

---

### 44. Что такое кросс-доменные рекомендации?

**Cross-domain RS** — перенос предпочтений пользователя между разными предметными областями:
- Книги → фильмы
- Видео → e-commerce

#### Применения:
- Cold start
- Дополнительные сигналы интереса
- Повышение разнообразия

#### Методы:
- Совместное латентное пространство
- Mapping функций между доменами
- Мета-обучение

---

### 45. Чем операция свёртки в CNN отличается от графовой свёртки?

#### CNN:
- Применяется к регулярным структурам (изображения, текст)
- Ядро свёртки "скользит" по фиксированной сетке

\[
y_{i,j} = \sum_{m,n} x_{i+m, j+n} \cdot w_{m,n}
\]

#### GCN (Graph Conv):
- Применяется к неструктурированным графам
- Обновление происходит через соседей:

\[
h_v^{(k+1)} = \text{AGG}(\{h_u^{(k)} : u \in \mathcal{N}(v)\})
\]

#### Отличия:

| Свёртка         | CNN                               | GCN                             |
|------------------|------------------------------------|----------------------------------|
| Данные            | Регулярная решетка                | Граф                            |
| Окружение         | Фиксированное окно                | Гибкое множество соседей        |
| Агрегация         | Фиксированная (матрица весов)     | Функция: mean/sum/attention     |
---

### 46. Что такое model-agnostic и model-intrinsic подходы? Примеры

#### Model-agnostic (вне зависимости от модели):
- Работает как "чёрный ящик"
- Можно использовать с любой моделью
- Примеры:
  - **LIME**: аппроксимирует модель локально
  - **SHAP**: оценивает вклад признаков
  - **Permutation Feature Importance**

#### Model-intrinsic (встроенные в модель):
- Интерпретация идёт из структуры модели
- Примеры:
  - **Weights в логистической регрессии**
  - **Attention в Transformer**
  - **Feature split importance в деревьях**

| Подход         | Примеры         | Применимость      |
|----------------|------------------|--------------------|
| Agnostic       | SHAP, LIME       | Универсально       |
| Intrinsic      | Attention, веса  | Только для моделей |

---

### 47. Типы перекрытия данных в cross-domain рекомендациях

1. **User-overlap**: один пользователь есть в обоих доменах
2. **Item-overlap**: один и тот же айтем встречается в обоих
3. **Feature-overlap**: пересекаются признаки айтемов/юзеров
4. **No-overlap**: нет общего, нужен transfer learning

| Перекрытие    | Пример                       |
|----------------|-------------------------------|
| User           | Один и тот же email в Netflix и Spotify |
| Item           | Книга доступна и на Amazon, и в Lib.ru |
| Feature        | Айтемы имеют одинаковые жанры |
| None           | Разные домены, обучаем mapping |

---

### 48. Что такое граф знаний и как его использовать в рекомендациях?

**Граф знаний** — семантический граф, где узлы — сущности, рёбра — отношения.

Пример:
- Узлы: фильм, актёр, жанр
- Рёбра: "играл", "жанр", "режиссёр"

#### Использование в RS:
1. **Feature enrichment**: добавление признаков к айтемам
2. **Path-based RS**: используем пути в графе как признаки
3. **GNN-based RS**: обучение на графе знаний
4. **KG-Aware MF**: объединим с латентной факторизацией

#### Пример моделей:
- **KGCN** (Knowledge Graph Convolutional Network)
- **RippleNet** (спред интересов через граф)

---

### 49. Бейзлайны для next basket prediction (NBP). Как считать популярность?

#### Бейзлайны:
- **Most popular**: топ частых айтемов
- **Repeat model**: повтор предыдущих покупок
- **Association rules**: "если A, то B"
- **Item2Vec / Prod2Vec**: эмбеддинги айтемов
- **FPMC**, **GRU4Rec**, **SASRec**

#### Подсчёт популярности:
\[
\text{Popularity}(i) = \frac{\text{count}(i)}{\sum_j \text{count}(j)}
\]

Может считаться по:
- количеству покупок
- уникальным пользователям
- недавним взаимодействиям

---

### 50. Отличия между batch и real-time рекомендациями. Когда нужен online?

#### Batch RS:
- Обновление рекомендаций раз в N часов
- Используется precomputed модели (ALS, LightGCN)
- Подходит для стабильных фидов

#### Real-time RS:
- Учитывает последние действия
- Использует session-based модели, faiss + nearest neighbors

#### Отличия:

| Характеристика     | Batch                        | Real-time                     |
|---------------------|-------------------------------|-------------------------------|
| Обновление         | Периодическое                  | Немедленное                   |
| Модели              | Pretrained                    | Online / lightweight          |
| Примеры             | ALS, LightGCN                 | GRU4Rec, Faiss + Recency      |

#### Когда делать online:
- В e-commerce, где сессия — главный источник интента
- Когда CTR сильно зависит от последнего действия
- При A/B тестировании с быстрым фидбеком

---

### 51. Что такое контент? Что такое контекст? Примеры

- **Контент (content)**: описание айтема или пользователя
  - Примеры: жанр фильма, цена, описание, эмбеддинг из текста

- **Контекст (context)**: внешние условия взаимодействия
  - Примеры: время суток, локация, устройство, сессия

| Параметр | Примеры                       |
|----------|-------------------------------|
| Контент  | возраст юзера, тег айтема     |
| Контекст | утро, Москва, с мобильного    |

---

### 52. Как работает DSSM? Какой лосс используется?

**DSSM (Deep Structured Semantic Model)** — двухбашенная нейросеть для матчинга (user, item):
- Одна башня обрабатывает пользователя, другая — айтем
- Выход: эмбеддинги \( u, v \)
- Сходство: cosine similarity или dot product:
  \[
  \hat{y}_{ui} = \frac{u \cdot v}{\|u\| \cdot \|v\|}
  \]

#### Loss:
- Cross-entropy (softmax over negatives)
- Triplet loss
- InfoNCE:
  \[
  \mathcal{L} = -\log \frac{\exp(\text{sim}(u, v^+))}{\sum_{j} \exp(\text{sim}(u, v_j))}
  \]

Применяется в:
- Поиске (query–document)
- Рекомендациях (user–item)

---

### 53. В чём идея beeFormer?

**beeFormer** — это архитектура рекомендательной модели, вдохновлённая поведением пчёл. Ключевая идея: агрегировать информацию от похожих пользователей/айтемов и направлять внимание как в self-attention, так и в cross-user/item attention.

#### Основные черты:
- Использует механизм **swarm attention**
- Адаптивно ищет релевантные элементы во всём пространстве
- Эффективен в ситуации с длинными последовательностями

#### Применения:
- session-based RS
- long-range dependencies

---

### 54. Зачем использовать последовательность?

Учет последовательности позволяет:
- Учитывать **порядок интересов** пользователя
- Захватывать **динамику предпочтений**
- Улучшать **контекстуальную релевантность**

#### Примеры:
- SASRec: self-attention поверх последовательности
- GRU4Rec: RNN на истории взаимодействий

Последовательность особенно важна в e-commerce и видео-рекомендациях, где действия пользователя идут цепочкой.

---

### 55. Как работает RNN?

**RNN (Recurrent Neural Network)** — нейросеть, где выход зависит от текущего входа и предыдущего состояния:
\[
h_t = \tanh(W x_t + U h_{t-1} + b)
\]

- \(h_t\): скрытое состояние
- Запоминает информацию о последовательности
- Проблема: **затухающие градиенты** → плохо работает на длинных последовательностях

---

### 56. В чём идея LSTM/GRU? Какую проблему они решают?

LSTM и GRU — разновидности RNN, разработанные для борьбы с **vanishing gradients** и запоминания долгосрочных зависимостей.

#### LSTM:
- Использует **ячейку памяти** и **3 гейта** (input, forget, output)
- Позволяет "решать", какую информацию сохранить/забыть

\[
c_t = f_t \cdot c_{t-1} + i_t \cdot \tilde{c}_t
\]

#### GRU:
- Более компактная архитектура
- Объединяет input и forget гейты

\[
h_t = (1 - z_t) \cdot h_{t-1} + z_t \cdot \tilde{h}_t
\]

---

### 57. Что такое fusion? В чём идея? Зачем это делать? Какие бывают типы fusion?

**Fusion** — объединение разных источников информации в модели (например, текст, изображение, числа).

#### Зачем:
- Использовать больше признаков
- Улучшить обобщающую способность
- Поддержать мультимодальность

#### Типы fusion:
1. **Early fusion** — объединение признаков на входе
2. **Late fusion** — объединение результатов разных моделей
3. **Hybrid fusion** — комбинация и того, и другого

Пример: объединить эмбеддинг текста описания и эмбеддинг изображения товара

---

### 58. Как обрабатывать категориальные признаки для подачи в нейросети (мультимодальные рекомендации)?

#### Основные способы:
1. **Embeddings**: каждому уникальному значению соответствует вектор
   \[
   \text{Emb}(x_{\text{cat}}) \in \mathbb{R}^d
   \]

2. **One-hot**: редко используется в DL из-за разреженности
3. **Target encoding**: для простых моделей, не рекомендуется в DL

#### Важно:
- Embedding dim ≈ \(d = \min(50, \text{size}^{0.25})\)
- Не забывать про rare-categories handling и padding

---

### 59. Как обрабатывать вещественные признаки для подачи в нейросети (мультимодальные рекомендации)?

#### Способы:
1. **Нормализация**:
   - min-max scaling
   - z-score (стандартизация)
   - log(x+1) — для перекошенных распределений

2. **Bucketization**:
   - Разбиение на бины → one-hot или embedding

3. **BatchNorm / LayerNorm**:
   - Улучшает стабильность обучения

#### Пример:
- Цена товара → log1p + нормализация + linear projection

---
