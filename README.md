## 1. Формальная постановка задачи

### Персональные рекомендации
- Пользователи: {u₁, ..., uₙ}
- Айтемы: {i₁, ..., iₘ}
- Матрица взаимодействий: R ∈ ℝⁿˣᵐ, где Rᵤᵢ — факт взаимодействия
- Цель: построить функцию r̂ᵤᵢ = f(u, i), предсказывающую интерес пользователя к айтему

Top-N:
    TopN(u) = argsortᵢ(f(u, i))[:N]

### Ранжирование поисковой выдачи
- Запросы: q ∈ Q, документы: d ∈ D
- Цель: ранжировать документы по релевантности f(q, d)

Общее: обе задачи сводятся к ранжированию объектов в заданном контексте (пользователь или запрос)

---

## 2. Типы функций ранжирования

| Тип       | Описание                       | Пример             | Учитывает порядок |
|-----------|--------------------------------|--------------------|-------------------|
| Pointwise | Релевантность по одному айтему | MSE, CrossEntropy  | ❌                |
| Pairwise  | Сравнение двух айтемов         | BPR, RankNet       | ⚠ Частично        |
| Listwise  | Ранжирование всего списка      | NDCG, ListNet      | ✅                |

### Примеры формул:

**Pointwise (MSE):**
    MSE = (1/n) * Σ (yᵢ - ŷᵢ)²

**Pairwise (BPR):**
    L = -log σ( r̂ᵤᵢ⁺ - r̂ᵤᵢ⁻ )

**Listwise (LambdaRank):**
    Направлено на оптимизацию метрик ранжирования, таких как NDCG

## 3. Разница между BPR и WARP

### BPR (Bayesian Personalized Ranking)
- Идея: обучать на парах (u, i⁺, i⁻), где i⁺ — положительный айтем, i⁻ — случайный негатив
- Loss-функция:
    L = -log σ( r̂ᵤᵢ⁺ - r̂ᵤᵢ⁻ )
- Прост в реализации, хорошо работает на implicit data
- Не учитывает точный ранг — только бинарное предпочтение

### WARP (Weighted Approximate Rank Pairwise)
- Идея: сэмплировать негативы до тех пор, пока не найдётся "трудный" (такой, что r̂ᵤᵢ⁻ > r̂ᵤᵢ⁺ - 1)
- Loss зависит от приближённого ранга:
    L ≈ Σ (1 / rank) * max(0, 1 + r̂ᵤᵢ⁻ - r̂ᵤᵢ⁺)

### Отличия:

| Характеристика     | BPR                       | WARP                          |
|--------------------|---------------------------|-------------------------------|
| Тип обучения       | Pairwise                  | Approximate Listwise          |
| Sampling           | Один негатив              | Несколько, до срабатывания    |
| Loss               | log-sigmoid разницы       | Зависит от ранга              |
| Скорость           | Быстрее                   | Дольше, но точнее на топ-N    |

### Гиперпараметры:
- Размер эмбеддингов (factors): 64–128
- Learning rate: 0.01–0.05
- Regularization: 0.01–0.1
- WARP: максимум негативных сэмплов, ранговый штраф

---

## 4. Метрики ранжирования

### Precision@k
    Precision@k = (# релевантных в топ-k) / k

### Recall@k
    Recall@k = (# релевантных в топ-k) / (# всех релевантных)

### MAP@k (Mean Average Precision)
    AP@k = (1 / min(m, k)) * Σ (Precision@i), где i — позиции релевантных айтемов
    MAP@k = среднее по всем пользователям

### NDCG@k (Normalized Discounted Cumulative Gain)
    DCG@k = rel₁ + Σ (relᵢ / log₂(i+1)), i = 2...k
    NDCG@k = DCG@k / IDCG@k (идеальный DCG)

---

## 5. Вопросы по NDCG@k

- **Достоинства:** учитывает позицию и релевантность, подходит для оценки топов
- **Недостатки:** не всегда интерпретируем, чувствителен к логике DCG
- **Зачем логарифм?** — штрафует более низкие позиции, придаёт больше веса верхним
- **Зачем экспонента в числителе?** — если используется gain = 2^rel - 1, то усиливается контраст между релевантностями
- **На каком уровне считается?** — на уровне пользователя, затем усредняется
- **Приводим ли к бинарному виду?** — часто да, но можно использовать и целые веса (0–3 и т.п.)

---

## 6. Может ли рост оффлайн метрик ухудшить онлайн?

Да. Примеры ситуаций:
- Модель переобучается на старые предпочтения (offline ↑, CTR ↓)
- Увеличивается diversity → хуже retention
- Метрика не учитывает позиции и визуальное оформление айтемов
- Пользователь кликает, но не доволен → оффлайн ok, онлайн плохо

**Типы связей:**
- Корреляция ≠ причинность
- Иногда оффлайн-метрика "обманывает" из-за сэмплинга, негатива и неучтённого контекста

---

## 7. Что такое матрица интеракций?

- Матрица R ∈ ℝⁿˣᵐ, где:
    - n — количество пользователей
    - m — количество айтемов
    - Rᵤᵢ = 1, если было взаимодействие (просмотр, клик), иначе 0
- Может быть бинарной или с весами (время, количество кликов и т.д.)
- Основа для CF, MF, ALS и др.

---

## 8. Explicit vs Implicit feedback

| Тип        | Пример данных          | Особенности                        |
|------------|------------------------|-------------------------------------|
| Explicit   | Оценки (1–5 звёзд)     | Чёткая метка, можно обучать регрессию |
| Implicit   | Клики, покупки, время  | Нет явной оценки, бинаризация или веса |

---

## 9. Способы задать взаимодействие (новостная лента)

- Бинаризация: просмотр → 1, нет → 0
- Взвешивание:
  - по dwell time (время на экране)
  - по глубине скролла
  - по типу действия (клик > просмотр > показ)
- Временная дискаунтация (чем новее, тем выше вес)
- Ограничение по сессиям

---

## 10. Рекомендации без моделей (user-/item-based similarity)

- **Item-based**:
    - cosine(i₁, i₂) между векторами взаимодействий
    - рекомендовать похожие на те, что юзер уже смотрел
- **User-based**:
    - искать k ближайших пользователей по похожим интересам
    - брать их популярные айтемы

Пример:
```python
sim(i1, i2) = cosine(R[:, i1], R[:, i2])
TopN(u) = items similar to seen by u
```

---

### 10. Пример рекомендаций без обучения модели

#### Item-based KNN:
- Считаем матрицу сходства между айтемами (косинусное, Jaccard и др.)
- Для каждого айтема находим похожие
- Рекомендуем пользователю айтемы, похожие на те, с которыми он уже взаимодействовал

#### User-based KNN:
- Находим пользователей с похожим поведением
- Рекомендуем айтемы, которые нравятся «соседям»

**Плюсы**: простота, интерпретируемость  
**Минусы**: плохо масштабируется, не учитывает латентные предпочтения

---

## 11. Что такое матричное разложение для рекомендательных систем? Отличия от коллаборативной фильтрации

Матричное разложение (Matrix Factorization) — это приближение матрицы взаимодействий R размерности (n_users × n_items) как произведения двух матриц меньшей размерности:

    R ≈ U · Vᵗ

где:
- U ∈ ℝⁿˣᵈ — матрица эмбеддингов пользователей
- V ∈ ℝᵐˣᵈ — матрица эмбеддингов айтемов
- d — размерность скрытого пространства (обычно 32–128)

Суть — представление пользователей и айтемов в общем пространстве, где скалярное произведение векторов uᵤ и vᵢ приближает интерес пользователя к айтему:

    ŷᵤᵢ = ⟨uᵤ, vᵢ⟩

**Отличия от классической коллаборативной фильтрации:**
- CF (user-based/item-based) не использует обучаемые эмбеддинги, а опирается на эвристические меры (например, cosine similarity).
- MF масштабируется лучше и работает в случае data sparsity.

---

## 12. Как MF позволяет избежать повторов в топ-N?

Факторизационные модели (например, ALS или BPR) строят эмбеддинги, отражающие интересы пользователя, и ранжируют все айтемы, включая новые и неинтерактированные. Айтемы, с которыми уже были взаимодействия, можно исключить из рекомендаций после ранжирования (пост-фильтрация).

Причина разнообразия:
- Обучение происходит на положительных и отрицательных взаимодействиях.
- Повтор взаимодействий не влияет на итоговую рекомендацию — модель учится отличать интересные от неинтересных айтемов.
- Итоговая top-N выдача — это "самые близкие" айтемы в латентном пространстве, которые ещё не были просмотрены.

---

## 13. Способы разбиения данных для оффлайн-оценки

| Метод         | Описание |
|---------------|----------|
| **Random Split** | Случайное деление взаимодействий на train/test |
| **User Split**   | Деление по пользователям |
| **Time-based split** | Использует временные метки, обучаемся на прошлом, тестируем на будущем |
| **Leave-one-out** | Для каждого пользователя последняя интеракция в test, остальные — в train |

**Наиболее валидный:** Time-based hold-out или Leave-one-out, так как имитируют реалистичный сценарий рекомендаций.

---

## 14. Что такое leave-one-out разбиение?

Leave-One-Out (LOO) — это стратегия, при которой:
- Для каждого пользователя берется **последнее** взаимодействие как test.
- Остальные — обучающая выборка.

Используется часто в implicit-сценариях.

Преимущества:
- Эффективно эмулирует предсказание "следующего действия".
- Подходит для top-N задач.

---

## 15. Как работает двухуровневая архитектура рекомендательной системы?

Двухуровневая (two-stage) архитектура включает два этапа:

1. **Retrieval (candidate generation)**:
   - Быстрое получение ~100–1000 кандидатов.
   - Используются модели: ALS, LightGCN, item2vec, KNN.
   - Оценка: простая (dot product, similarity).

2. **Ranking**:
   - Точный пересчет скорингов для кандидатов.
   - Используются ML-модели: GBM, DNN, DSSM.
   - Учитываются дополнительные фичи: контекст, временные признаки, device, session info и т.п.

Преимущества:
- Комбинирует масштаб и точность.
- Экономит ресурсы, так как сложная модель не применяется ко всем айтемам.

---

## 16. Можно ли использовать градиентный бустинг для ранжирования? Преимущества перед нейросетями

Да, градиентный бустинг (например, LightGBM, XGBoost) часто используется для задачи ранжирования.

### Преимущества бустинга:
- Не требует масштабирования признаков.
- Эффективно работает на табличных данных (features из логов, профиля, контекста).
- Устойчив к шумам, хорошо работает с категориальными фичами (с энкодингом).
- Быстро обучается и легко дебажится.
- Поддерживает различные ранжирующие loss'ы (rank:pairwise, rank:ndcg и т.п.).

### Недостатки:
- Хуже захватывает сложные зависимости, чем нейросети.
- Требует ручного инжиниринга признаков.
- Не масштабируется на миллионы пользователей/айтемов так же легко, как light-версии нейросетей.

Используется как второй уровень в two-stage системах.

---

## 17. Когда стоит (не) рекомендовать уже взаимодействованные айтемы?

### Когда не стоит рекомендовать:
- В случае one-time interaction (например, покупка билета, регистрация).
- Когда цель — новизна, расширение интересов.
- Если есть ограничения бизнеса (нельзя второй раз купить, например, подписку).

### Когда можно оставить:
- В сценариях повторных покупок (фрукты, бытовая химия).
- Если взаимодействие неполное (например, добавлено в корзину — но не куплено).
- В случае коротких сессий, где пользователь может забыть, что уже видел.

**Вывод:** всё зависит от задачи — можно исключать айтемы постфактум из рекомендаций, если необходимо.

---

## 18. Что такое гибридная рекомендательная система?

Гибридная система — это комбинация нескольких подходов (например, CF, контентный, knowledge-based и др.), чтобы:
- Улучшить покрытие и качество.
- Снизить проблемы холодного старта.
- Повысить устойчивость к ошибкам одного из методов.

### Основные типы гибридизации:
- **Weighted** — усреднение скорингов разных моделей.
- **Switching** — выбор модели в зависимости от условий (см. вопрос 30).
- **Mixed** — объединение результатов.
- **Cascade** — одна модель отбирает кандидатов, другая ранжирует.
- **Feature-level** — признаки из одной модели подаются в другую.

---

## 19. Какие рекомендательные подходы не зависят от домена?

Подходы, которые не требуют специфических знаний о предметной области:

- **Collaborative filtering** (user/item-based) — работает на взаимодействиях.
- **Matrix factorization** — только user/item ID.
- **Graph-based методы** (LightGCN, random walks) — используют структуру, но не контент.
- **Sequence-based** (например, SASRec) — основаны на последовательностях.

Все эти методы применимы в любом домене при наличии данных о взаимодействии.

---

## 20. Что такое popular bias?

Popular bias — смещение модели в сторону популярных айтемов.

### Причины:
- Частые взаимодействия с популярными товарами => модель переобучается на них.
- Метрики вроде Recall@k могут поощрять это поведение.

### Последствия:
- Потеря разнообразия и новизны.
- Рекомендации становятся однообразными.
- Хвостовая часть каталога игнорируется.

### Способы борьбы:
- Downsampling популярных айтемов.
- Использование diversity-aware метрик.
- Взвешивание при обучении (inverse popularity).

---

## 21. Что такое проблема холодного старта? Как её решать?

**Проблема холодного старта** возникает, когда:
- В системе появляются **новые пользователи** без истории.
- Или добавлены **новые айтемы**, по которым нет взаимодействий.

### Решения:
- **Для новых пользователей**:
  - Использовать демографические и контекстные фичи.
  - Предложить опрос (onboarding).
  - Content-based рекомендации (по интересам).

- **Для новых айтемов**:
  - Использовать контентные признаки (описание, категории).
  - Использовать мета-информацию (цена, бренд).
  - Knowledge graph (например, item2vec от соседей по графу).

- **Модели**:
  - LightFM — сочетает CF и контент.
  - DSSM — объединяет эмбеддинги фичей и взаимодействий.
  - Zero-shot learning, meta-learning для cold start.

---

## 22. Метрики novelty, diversity, coverage, serendipity

| Метрика       | Что измеряет                  | Пример формулы/идеи |
|---------------|-------------------------------|----------------------|
| **Novelty**   | Насколько рекомендации "новые" для пользователя | Популярность айтемов в выдаче |
| **Diversity** | Разнообразие внутри рекомендаций | Среднее расстояние между айтемами |
| **Coverage**  | Доля каталога, охваченная рекомендациями | |RecItems| / |AllItems| |
| **Serendipity** | Удивительность и польза одновременно | Разность между ожидаемым и полученным с положительным фидбеком |

Часто считаются вместе с точностью. Можно поощрять diversity и novelty через loss или re-ranking.

---

## 23. Что такое проблема feedback loop?

Feedback loop — это замкнутый цикл, при котором:
- Система рекомендует то, что пользователь уже и так видит.
- Пользователь кликает — модель усиливает уверенность.
- Новые/редкие айтемы не попадают в рекомендации.

**Итог:** система становится узконаправленной и ухудшает качество рекомендаций в долгосрочной перспективе.

### Решения:
- Exploration (рандомизация, epsilon-greedy).
- Моделирование non-exposure.
- Контроль diversity/novelty.
- A/B тесты для введения нового контента.

---

## 24. Что такое проблема информационного пузыря (information bubble)?

**Information bubble** = персонализация приводит к изоляции.

### Причина:
- Модель "узнает" интересы пользователя и начинает рекомендовать только релевантные вещи.
- Это ограничивает кругозор, снижает novelty.

### Примеры:
- В соцсетях: пользователь видит только посты, подтверждающие его мнение.
- В рекомендациях — отсутствие новых категорий товаров.

**Решения**:
- Добавлять diversity и serendipity.
- Ротация категории.
- Смешанные рекомендации (explore + exploit).

---

## 25. В чём разница между оффлайн и онлайн метриками?

| Тип метрики   | Описание |
|---------------|----------|
| **Оффлайн**   | Считаются на подготовленных разбиениях (Recall@k, NDCG@k, Precision). Быстро и дёшево. |
| **Онлайн**    | Измеряются в проде: CTR, конверсии, удержание. Показывают реальное поведение. |

### Почему они могут расходиться:
- Оффлайн метрики не учитывают bias (позиции, UI).
- Пользователи могут реагировать не на "лучший скор", а на оформление, контекст, момент.

**Вывод:** оффлайн = быстрая проверка; онлайн — финальное подтверждение гипотезы.

---

### 26. Почему не все айтемы могут быть доступны пользователю?

Рекомендательная система не всегда может рекомендовать все айтемы из каталога:

- **Физические ограничения**: товар закончился, нет в наличии, снят с продажи.
- **Юридические ограничения**: ограничения по региону, возрасту, лицензии.
- **Бизнес-ограничения**: исключения по бренду, фильтры платформы.
- **Пользовательские фильтры**: пользователь уже купил/лайкнул айтем или скрыл его.

➡️ В продакшене важно фильтровать недоступные айтемы ДО ранжирования или учитывать это в самой модели.

---

### 27. Что такое монотонные ограничения?

**Монотонные ограничения (monotonic constraints)** — это требования, что с увеличением значения признака модель должна увеличивать или уменьшать результат предсказания строго в одном направлении.

#### Пример:
Если увеличивается `user_rating`, то модель должна увеличивать предсказанную вероятность покупки.

#### Где применяются:
- В LightGBM, CatBoost и других GBDT-моделях:
  ```python
  lgb.train(params, train_set, ..., params={'monotone_constraints': [1, -1, 0]})
  ```

➡️ Они повышают интерпретируемость и стабильность, особенно в задачах с бизнес-ограничениями.

---

### 28. Как интерпретировать рекомендации с помощью SHAP-values?

**SHAP (SHapley Additive Explanations)** объясняет вклад каждого признака в предсказание модели.

#### Как работает:
- Оценивает, насколько каждый признак повлиял на рекомендацию (score).
- Строится на базе идей кооперативной теории игр (Shapley values).

#### Пример использования:
```python
import shap
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_val)
shap.summary_plot(shap_values, X_val)
```

➡️ Особенно полезен для:
- Поддержки доверия пользователя.
- Отладки модели.
- Соответствия требованиям прозрачности (например, GDPR).

---

### 29. Может ли модель второго уровня учитывать сезонность и как?

Да, модель второго уровня (ранкер) может учитывать сезонность через:

#### Временные признаки:
- `hour`, `dayofweek`, `month`, `is_weekend`, `is_holiday`
- Кол-во взаимодействий за последние N дней
- Time-since-last-interaction

#### Представление:
- One-hot кодирование
- Date embeddings (в DL)
- Перекрёстные признаки: `user × day`, `category × hour`

➡️ Также можно учитывать сезонность на уровне фильтрации айтемов (например, летом — пляжные товары).

---

### 30. Что такое switching в гибридных рекомендательных системах?

**Switching** — это подход, при котором выбор рекомендательной модели зависит от ситуации.

#### Пример логики:
```text
if user is new:
    use content-based filtering
elif item is new:
    use popularity-based recommendation
else:
    use collaborative filtering
```

#### Преимущества:
- Высокая адаптивность.
- Покрытие разных cold-start сценариев.

#### Недостатки:
- Требует качественной логики переключения.
- Возможны граничные ошибки (jump behavior).

➡️ Switching — простой, но эффективный способ комбинировать сильные стороны разных подходов.

---

### 31. Как работает implicit ALS? Можно ли добавить признаки и учесть время?

Implicit ALS (Alternating Least Squares) — метод матричной факторизации для неявных взаимодействий. Модель минимизирует ошибку:

    L = ∑_ui [ c_ui * (p_ui - uᵀv)² ] + λ (||u||² + ||v||²)

Где:
- `p_ui = 1`, если есть взаимодействие, иначе `0`
- `c_ui = 1 + α * r_ui` — уверенность в интеракции

Контентные признаки можно добавить, расширяя векторы `u`, `v`. Временные аспекты можно учесть через:
- Взвешивание `c_ui` по времени (например, с экспоненциальным затуханием)
- Временные срезы и тренировку отдельных моделей

**Плюсы**:
- Эффективен, особенно на больших sparse-матрицах
- Реализован на GPU

**Минусы**:
- Линейная модель, не учитывает порядок действий

---

### 32. Как работает userKNN / itemKNN? Плюсы и минусы

Оба метода используют сходство между пользователями или айтемами.

UserKNN:

    r̂_ui = ∑_v sim(u, v) * r_vi / ∑_v |sim(u, v)|

ItemKNN:

    r̂_ui = ∑_j sim(i, j) * r_uj / ∑_j |sim(i, j)|

Симметричная метрика может быть cosine, Pearson, Jaccard.

**Плюсы**:
- Простота, интерпретируемость
- Хорошо работает при наличии плотных соседей

**Минусы**:
- Плохо масштабируется
- Не обобщает на новые айтемы/юзеров

---

### 33. Как устроена модель EASE? Сравнение с SLIM

EASE — линейная модель (autoencoder), обучающая матрицу весов W для восстановления интеракций:

    W = (XᵀX + λI)⁻¹ XᵀX
    W_diag = 0

SLIM — также линейная модель, но обучается через оптимизацию с регуляризацией:

    Minimize ||X - XW||² + α||W||₁ + λ||W||²

**Сравнение**:
- EASE: быстро решается аналитически, но не sparse
- SLIM: sparse, но обучается дольше

---

### 34. Как работает LightFM? Плюсы и минусы

LightFM — обобщённая модель MF с признаками:

    r̂_ui = (p_u + ∑ x_f)ᵀ (q_i + ∑ y_g)

Где:
- `p_u`, `q_i` — эмбеддинги пользователя и айтема
- `x_f`, `y_g` — эмбеддинги признаков (тегов, категорий и т.д.)

Поддерживает loss-функции: logistic, BPR, WARP.

**Плюсы**:
- Поддерживает cold-start
- Объединяет content-based и CF

**Минусы**:
- Зависит от качества признаков
- Не учитывает порядок взаимодействий

---

## Вопросы 36–40. BERT4Rec, SASRec, LightGCN, VAE и MultiVAE

### 36. Как работает BERT4Rec? Преимущества и недостатки

BERT4Rec — это двунаправленная self-attention модель для рекомендаций, аналогичная BERT из NLP.

**Принцип:**
- На вход подаются последовательности айтемов `[i₁, i₂, ..., i_t]`
- Случайные айтемы маскируются: `i_k → [MASK]`
- Модель обучается предсказывать скрытые айтемы по контексту с обеих сторон

**Loss:** cross-entropy между предсказанным и истинным айтемом:
    
    L = - ∑_masked log P(i_k | контекст)

**Плюсы:**
- Учитывает контекст с обеих сторон (в отличие от SASRec)
- Обучается быстрее на параллельных данных

**Минусы:**
- Не всегда пригоден для предсказания следующего айтема (non-causal)
- Высокие требования к памяти

---

### 37. Отличия BERT4Rec и SASRec

| Аспект          | BERT4Rec                         | SASRec                             |
|-----------------|----------------------------------|------------------------------------|
| Механизм        | Bidirectional Transformer        | Causal Transformer (left-to-right)|
| Обучение        | Masked item prediction           | Next-item prediction               |
| Loss            | Cross-Entropy по маскам          | Cross-Entropy на следующий айтем   |
| Последовательность | Учитывает всю историю и будущее | Только прошлое                     |
| Инференс        | Требуется полная последовательность | Последний hidden state             |

**Вывод:** SASRec лучше для онлайн-предсказаний, BERT4Rec — для оффлайн обобщений.

---

### 38. Как работает LightGCN?

LightGCN — упрощённый графовый рекомендательный алгоритм.

**Идея:**
- Представить пользователей и айтемы как граф: ребро = интеракция
- Эмбеддинги обновляются через усреднение соседей:

    e_u^(k+1) = ∑_{i ∈ N(u)} (1/√(|N(u)||N(i)|)) * e_i^(k)

- Итоговый эмбеддинг:

    e_u = ∑_{k=0}^K e_u^(k)

**Плюсы:**
- Нет нелинейностей и весов — быстрее и проще
- Хорошо работает при глубоком распространении (больше hops)

**Минусы:**
- Не учитывает порядок
- Не обучает веса на ребрах (в отличие от GAT)

---

### 39. Как получить рекомендации из вариационного автоэнкодера (VAE)?

Обученный VAE восстанавливает вероятности айтемов по вектору латентного пространства `z`.

**Процесс:**
1. Для каждого пользователя: вектор интеракций `x`
2. Кодируется в `z ~ N(μ(x), σ²(x))`
3. Восстановление вероятностей `x̂ = decoder(z)`
4. Ранжируем по `x̂_i`

**Рекомендации:**
- Исключаем уже взаимодействовавшие айтемы
- Берем top-k по `x̂`

---

### 40. Как работает MultiVAE? Отличия от MultiDAE

**MultiVAE:**
- Обучает вероятностное распределение: `z ~ N(μ, σ²)`
- Использует регуляризацию через KL-дивергенцию:

    L = E_q [log p(x | z)] - β * KL[q(z|x) || p(z)]

**MultiDAE:**
- Детерминированный autoencoder без стохастичности
- Нет KL-потерь

**Сравнение:**
- MultiVAE — лучше обобщает (регуляризация), подходит для sparse
- MultiDAE — быстрее, стабильнее, но склонен к переобучению

**Плюсы MultiVAE:**
- Универсальность, устойчивость к шуму
- Подходит для холодного старта

**Минусы:**
- Сложнее в обучении
- Чувствителен к гиперпараметру β

---

## Вопросы 41–45. Объяснения, Uplift, Multi-task, Cross-domain, CNN vs GCN

### 41. Как можно делать объяснения рекомендаций?

**Подходы к объяснению рекомендаций:**

- **Model-intrinsic** (встроенные):
  - Модели дают интерпретацию прямо из структуры (например, Rule-based, kNN)
  - Пример: в userKNN можно указать похожих пользователей и их действия

- **Model-agnostic** (внешние):
  - Построение объяснений поверх чёрного ящика
  - Пример: SHAP, LIME — оценивают вклад признаков в финальное решение

**Методы:**
- Использование content-признаков (жанры, бренды)
- Граф объяснений (item → мета-факт → пользователь)
- Attention-механизмы (в DL-моделях, например SASRec)

---

### 42. Что такое uplift-рекомендации?

**Uplift-рекомендации** — это рекомендации, ориентированные на **изменение поведения пользователя** от показа.

**Ключевая идея:** не просто вероятность клика, а **разница в поведении с рекомендацией и без неё**.

**Uplift = P(y=1 | treatment) - P(y=1 | control)**

**Примеры моделей:**
- Two-model: обучаем две модели (treatment/control)
- Uplift trees (causal trees)
- Meta-learners: T-Learner, S-Learner, X-Learner

**Применения:**
- Увеличение ретенции, A/B тесты
- Персонализированный маркетинг

---

### 43. Пример Multi-task обучения и архитектура

**Пример задач:**
- Предсказать:
  - Клик (binary classification)
  - Покупку (binary)
  - Время до следующего взаимодействия (regression)
  - Отток (binary)

**Архитектура:**
- Общая backbone-модель (например, shared embeddings + Transformer)
- Несколько выходов (multi-head):
  - Один head для CTR
  - Один head для conversion
  - Один head для time-to-event

**Плюсы:**
- Общие признаки обучаются эффективнее
- Улучшается генерализация

---

### 44. Что такое кросс-доменные рекомендации?

**Cross-domain recommendations** — это перенос знаний между разными предметными областями (доменами), например:

- **Источник**: музыка, **Цель**: книги
- **Источник**: поведение на одном сайте, **Цель**: другой сайт

**Зачем:**
- Решение проблемы холодного старта
- Мало данных в одном домене
- Выявление общих интересов пользователя

**Методы:**
- Совмещение эмбеддингов
- Перенос моделей (transfer learning)
- Графы соответствий между айтемами

---

### 45. Разница между сверткой в CNN и графовой сверткой (GCN)

| Аспект        | CNN                              | GCN                                      |
|---------------|----------------------------------|------------------------------------------|
| Структура     | Регулярная (матрица/изображение) | Нерегулярная (граф)                      |
| Соседство     | Фиксированное (например, 3x3)     | Определяется графом                      |
| Агрегация     | Взвешенная свертка ядром          | Усреднение/агрегация соседей             |
| Пример        | Изображения                      | Соцсети, айтем-графы                     |

**Формула GCN (1 слой):**

    hᵢ' = σ( ∑_{j ∈ N(i)} (1 / sqrt(|N(i)||N(j)|)) * W * hⱼ )

**Вывод:** CNN применимы к изображениям, GCN — к структурам со связями.

---

## Вопросы 46–50. Интерпретация, Cross-domain, Граф знаний, NBR, Online/Batch

### 46. Что такое model-agnostic и model-intrinsic подходы? Примеры

| Подход             | Описание                                               | Примеры                      |
|--------------------|--------------------------------------------------------|------------------------------|
| **Model-intrinsic** | Интерпретация встроена в модель                        | Decision Tree, kNN, FM       |
| **Model-agnostic**  | Объяснение независимо от модели                       | SHAP, LIME, Permutation test |

**Примеры:**
- FM объясняет вклад каждой фичи
- SHAP для XGBoost/LGBM показывает важность признаков
- Attention в Transformer даёт интерпретацию внимания

---

### 47. Типы перекрытия в cross-domain рекомендациях

Перекрытие может быть:

- **По пользователям (user overlap)**  
  Пример: один и тот же пользователь смотрит фильмы и слушает музыку

- **По айтемам (item overlap)**  
  Пример: книги, доступные и в e-commerce, и в библиотеке

- **По признакам (feature overlap)**  
  Пример: общие жанры, метаинформация, embeddings

**Нет перекрытия?** — используются методы переноса знаний: adversarial learning, pretraining, meta-learning.

---

### 48. Что такое граф знаний и его применение в рекомендациях

**Граф знаний (Knowledge Graph)** — это структура, где вершины — сущности (item, user, category), а рёбра — связи между ними.

**Пример:**  
`User → likes → Movie`,  
`Movie → has_genre → Action`

**Использование в RecSys:**
- Расширение профиля пользователя
- Объяснение рекомендаций через связи
- Построение путей (path-based features)
- GNN на графе знаний (например, KGCN)

**Плюсы:**
- Семантическое обогащение
- Работа с холодным стартом
- Explainability

---

### 49. Бейзлайны и популярность в next basket prediction (NBR)

**Статистические бейзлайны:**
- **Most Popular** — топ-N самых популярных товаров
- **Recency** — последние покупки

**Модельные бейзлайны:**
- RNN / GRU / LSTM на последовательности
- TransRec, NARM
- Session-based kNN

**Подсчёт популярности:**
```text
pop_i = count(user-item interactions for item i)
```
или с логарифмической нормализацией:
```text
pop_i = log(1 + freq_i)
```

---

### 50. Отличия batch vs real-time рекомендаций и критерии online

| Характеристика       | Batch                                | Real-time                            |
|----------------------|---------------------------------------|--------------------------------------|
| Обновление модели    | Раз в сутки/неделю                   | Постоянно, по ходу событий           |
| Примеры              | ALS, Matrix Factorization             | Online CTR, Streaming SASRec         |
| Latency              | Низкие требования                     | Критична (мс)                        |
| Персонализация       | Ограниченная                          | Очень высокая                        |

**Когда делать online:**
- Высокочастотные изменения (новости, реклама)
- Нужно быстро реагировать на действия юзера
- Контекст важен (время суток, устройство)

**Гибрид:** частично batch + частично real-time (например, feature store + online reranker)

---

## Вопросы 51–55. Контент, DSSM, beeFormer, последовательность, RNN

### 51. Что такое контент и контекст?

- **Контент** — это свойства айтема или пользователя, **не зависящие от внешней среды**.
  - Примеры:
    - Айтем: жанр фильма, длина видео, бренд товара
    - Пользователь: возраст, интересы, локация

- **Контекст** — это факторы, **влияющие на поведение пользователя во время взаимодействия**.
  - Примеры:
    - Время суток
    - Устройство (мобильный/десктоп)
    - Локация в момент взаимодействия
    - Состояние погоды

Контекст может меняться динамически, контент — нет.

---

### 52. Как работает DSSM? Какой лосс используется?

**DSSM (Deep Structured Semantic Model)** — модель для сопоставления пары `(user, item)` в общем эмбеддинг-пространстве.

- Вход: две ветки нейросети
  - Левая: текст/фичи пользователя
  - Правая: текст/фичи айтема
- Обе ветки сжимаются в эмбеддинги: \( \mathbf{u}, \mathbf{v} \)
- Подсчёт сходства: косинусное расстояние или скалярное произведение

**Loss-функция:**
```text
L = -log( softmax( uᵗv⁺ / (uᵗv⁺ + Σ uᵗv⁻ₖ) ) )
```
Где:
- \( v^+ \): положительный айтем
- \( v^-_k \): отрицательные айтемы (негативный сэмплинг)

---

### 53. В чём идея beeFormer?

**beeFormer** — это специализированный трансформер для рекомендательных систем с focus attention.

Ключевые идеи:
- Учитывает **поведение** пользователя в сессии, как "пчела" переключается между цветами
- Селективное внимание: не на все айтемы, а на наиболее релевантные в истории
- Возможна агрегация **внешнего контекста** (время, платформа)

Преимущество — лучшая устойчивость к длинным/шумным историям и высокая explainability.

---

### 54. Зачем использовать последовательность?

Порядок взаимодействий важен:
- Показывает **динамику интересов**
- Помогает предсказать следующий шаг

Примеры применения:
- Сессийные рекомендации (последнее действие)
- NBR (next basket prediction)
- Трендовые/временные предпочтения

Модели: RNN, Transformer, SASRec, GRU4Rec

---

### 55. Как работает RNN?

**RNN (Recurrent Neural Network)** обрабатывает вход как последовательность: каждый элемент зависит от предыдущего состояния.

Обновление состояния:
```text
hₜ = tanh( Wₓxₜ + Wₕhₜ₋₁ + b )
```

- \( x_t \): вход на шаге \( t \)
- \( h_t \): скрытое состояние
- Проблемы: **затухающие градиенты**, плохо запоминает долгие зависимости

Применяется в рекомендациях для учета истории пользователя.

---

### 56. В чём идея LSTM / GRU? Какую проблему они решают?

**LSTM (Long Short-Term Memory)** и **GRU (Gated Recurrent Unit)** — это модификации RNN, которые решают проблему **затухающих градиентов** и **запоминания долгосрочной зависимости**.

#### LSTM:
- Использует **ячейку памяти** и **входные/выходные/забывающие гейты**
- Обновление:
  ```text
  fₜ = σ(W_f · [hₜ₋₁, xₜ])        (forget gate)
  iₜ = σ(W_i · [hₜ₋₁, xₜ])        (input gate)
  oₜ = σ(W_o · [hₜ₋₁, xₜ])        (output gate)
  Cₜ = fₜ * Cₜ₋₁ + iₜ * tanh(W_C · [hₜ₋₁, xₜ])
  hₜ = oₜ * tanh(Cₜ)
  ```

#### GRU:
- Упрощённая версия LSTM с двумя гейтами:
  ```text
  zₜ = σ(W_z · [hₜ₋₁, xₜ])        (update gate)
  rₜ = σ(W_r · [hₜ₋₁, xₜ])        (reset gate)
  hₜ = (1 - zₜ) * hₜ₋₁ + zₜ * tanh(W · [rₜ * hₜ₋₁, xₜ])
  ```

**Обе решают** проблему долгосрочной памяти и улучшают обучение последовательностей.

---

### 57. Что такое fusion? Зачем это нужно? Какие бывают типы?

**Fusion** — это объединение признаков из разных модальностей (например, текст, изображение, клики) в одну модель.

#### Зачем:
- Повышает точность рекомендаций
- Учитывает больше сигналов
- Делает модель более универсальной

#### Типы fusion:
| Тип             | Пример                                      | Особенность                        |
|------------------|---------------------------------------------|-------------------------------------|
| **Early Fusion** | Конкатенация всех признаков на входе        | Прост в реализации                 |
| **Late Fusion**  | Объединение выходов моделей после обучения  | Гибкость, можно обучать отдельно   |
| **Hybrid Fusion**| Комбинация признаков и решений              | Сложнее, но мощнее                 |

---

### 58. Как обрабатывать категориальные признаки в нейросетях?

Для подачи категориальных признаков (например, `item_id`, `genre`, `user_country`) используют **эмбеддинги**:

```python
# PyTorch
embedding = nn.Embedding(num_categories, embedding_dim)
```

- Каждой категории сопоставляется вектор: `Embedding[item_id] → [0.2, -0.5, ..., 0.1]`
- Эмбеддинги обучаются вместе с моделью
- Можно использовать one-hot → Embedding или заранее обученные эмбеддинги

**Важно**: нормализовать индексы и аккуратно обращаться с редкими категориями (регуляризация, cut-off по частоте).

---

### 59. Как обрабатывать вещественные признаки в нейросетях?

Подходы к числовым признакам (`price`, `rating`, `duration`):

1. **Нормализация** (обязательно!):
   - Мин-макс: `x' = (x - min) / (max - min)`
   - Стандартизация: `x' = (x - μ) / σ`
2. **Лог-трансформация** — если распределение скошено:
   ```text
   x' = log(1 + x)
   ```
3. **Бининг**: разбить на интервалы и закодировать категориально

Входы подаются в fully-connected слой (или через MLP-блоки), иногда комбинируются с эмбеддингами.

---
