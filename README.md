## 1. Формальная постановка задачи

### Персональные рекомендации
- Пользователи: {u₁, ..., uₙ}
- Айтемы: {i₁, ..., iₘ}
- Матрица взаимодействий: R ∈ ℝⁿˣᵐ, где Rᵤᵢ — факт взаимодействия
- Цель: построить функцию r̂ᵤᵢ = f(u, i), предсказывающую интерес пользователя к айтему

Top-N:
    TopN(u) = argsortᵢ(f(u, i))[:N]

### Ранжирование поисковой выдачи
- Запросы: q ∈ Q, документы: d ∈ D
- Цель: ранжировать документы по релевантности f(q, d)

Общее: обе задачи сводятся к ранжированию объектов в заданном контексте (пользователь или запрос)

---

## 2. Типы функций ранжирования

| Тип       | Описание                       | Пример             | Учитывает порядок |
|-----------|--------------------------------|--------------------|-------------------|
| Pointwise | Релевантность по одному айтему | MSE, CrossEntropy  | ❌                |
| Pairwise  | Сравнение двух айтемов         | BPR, RankNet       | ⚠ Частично        |
| Listwise  | Ранжирование всего списка      | NDCG, ListNet      | ✅                |

### Примеры формул:

**Pointwise (MSE):**
    MSE = (1/n) * Σ (yᵢ - ŷᵢ)²

**Pairwise (BPR):**
    L = -log σ( r̂ᵤᵢ⁺ - r̂ᵤᵢ⁻ )

**Listwise (LambdaRank):**
    Направлено на оптимизацию метрик ранжирования, таких как NDCG

## 3. Разница между BPR и WARP

### BPR (Bayesian Personalized Ranking)
- Идея: обучать на парах (u, i⁺, i⁻), где i⁺ — положительный айтем, i⁻ — случайный негатив
- Loss-функция:
    L = -log σ( r̂ᵤᵢ⁺ - r̂ᵤᵢ⁻ )
- Прост в реализации, хорошо работает на implicit data
- Не учитывает точный ранг — только бинарное предпочтение

### WARP (Weighted Approximate Rank Pairwise)
- Идея: сэмплировать негативы до тех пор, пока не найдётся "трудный" (такой, что r̂ᵤᵢ⁻ > r̂ᵤᵢ⁺ - 1)
- Loss зависит от приближённого ранга:
    L ≈ Σ (1 / rank) * max(0, 1 + r̂ᵤᵢ⁻ - r̂ᵤᵢ⁺)

### Отличия:

| Характеристика     | BPR                       | WARP                          |
|--------------------|---------------------------|-------------------------------|
| Тип обучения       | Pairwise                  | Approximate Listwise          |
| Sampling           | Один негатив              | Несколько, до срабатывания    |
| Loss               | log-sigmoid разницы       | Зависит от ранга              |
| Скорость           | Быстрее                   | Дольше, но точнее на топ-N    |

### Гиперпараметры:
- Размер эмбеддингов (factors): 64–128
- Learning rate: 0.01–0.05
- Regularization: 0.01–0.1
- WARP: максимум негативных сэмплов, ранговый штраф

---

## 4. Метрики ранжирования

### Precision@k
    Precision@k = (# релевантных в топ-k) / k

### Recall@k
    Recall@k = (# релевантных в топ-k) / (# всех релевантных)

### MAP@k (Mean Average Precision)
    AP@k = (1 / min(m, k)) * Σ (Precision@i), где i — позиции релевантных айтемов
    MAP@k = среднее по всем пользователям

### NDCG@k (Normalized Discounted Cumulative Gain)
    DCG@k = rel₁ + Σ (relᵢ / log₂(i+1)), i = 2...k
    NDCG@k = DCG@k / IDCG@k (идеальный DCG)

---

## 5. Вопросы по NDCG@k

- **Достоинства:** учитывает позицию и релевантность, подходит для оценки топов
- **Недостатки:** не всегда интерпретируем, чувствителен к логике DCG
- **Зачем логарифм?** — штрафует более низкие позиции, придаёт больше веса верхним
- **Зачем экспонента в числителе?** — если используется gain = 2^rel - 1, то усиливается контраст между релевантностями
- **На каком уровне считается?** — на уровне пользователя, затем усредняется
- **Приводим ли к бинарному виду?** — часто да, но можно использовать и целые веса (0–3 и т.п.)

---

## 6. Может ли рост оффлайн метрик ухудшить онлайн?

Да. Примеры ситуаций:
- Модель переобучается на старые предпочтения (offline ↑, CTR ↓)
- Увеличивается diversity → хуже retention
- Метрика не учитывает позиции и визуальное оформление айтемов
- Пользователь кликает, но не доволен → оффлайн ok, онлайн плохо

**Типы связей:**
- Корреляция ≠ причинность
- Иногда оффлайн-метрика "обманывает" из-за сэмплинга, негатива и неучтённого контекста

---

## 7. Что такое матрица интеракций?

- Матрица R ∈ ℝⁿˣᵐ, где:
    - n — количество пользователей
    - m — количество айтемов
    - Rᵤᵢ = 1, если было взаимодействие (просмотр, клик), иначе 0
- Может быть бинарной или с весами (время, количество кликов и т.д.)
- Основа для CF, MF, ALS и др.

---

## 8. Explicit vs Implicit feedback

| Тип        | Пример данных          | Особенности                        |
|------------|------------------------|-------------------------------------|
| Explicit   | Оценки (1–5 звёзд)     | Чёткая метка, можно обучать регрессию |
| Implicit   | Клики, покупки, время  | Нет явной оценки, бинаризация или веса |

---

## 9. Способы задать взаимодействие (новостная лента)

- Бинаризация: просмотр → 1, нет → 0
- Взвешивание:
  - по dwell time (время на экране)
  - по глубине скролла
  - по типу действия (клик > просмотр > показ)
- Временная дискаунтация (чем новее, тем выше вес)
- Ограничение по сессиям

---

## 10. Рекомендации без моделей (user-/item-based similarity)

- **Item-based**:
    - cosine(i₁, i₂) между векторами взаимодействий
    - рекомендовать похожие на те, что юзер уже смотрел
- **User-based**:
    - искать k ближайших пользователей по похожим интересам
    - брать их популярные айтемы

Пример:
```python
sim(i1, i2) = cosine(R[:, i1], R[:, i2])
TopN(u) = items similar to seen by u
```

---

### 10. Пример рекомендаций без обучения модели

#### Item-based KNN:
- Считаем матрицу сходства между айтемами (косинусное, Jaccard и др.)
- Для каждого айтема находим похожие
- Рекомендуем пользователю айтемы, похожие на те, с которыми он уже взаимодействовал

#### User-based KNN:
- Находим пользователей с похожим поведением
- Рекомендуем айтемы, которые нравятся «соседям»

**Плюсы**: простота, интерпретируемость  
**Минусы**: плохо масштабируется, не учитывает латентные предпочтения

---

## 11. Что такое матричное разложение для рекомендательных систем? Отличия от коллаборативной фильтрации

Матричное разложение (Matrix Factorization) — это приближение матрицы взаимодействий R размерности (n_users × n_items) как произведения двух матриц меньшей размерности:

    R ≈ U · Vᵗ

где:
- U ∈ ℝⁿˣᵈ — матрица эмбеддингов пользователей
- V ∈ ℝᵐˣᵈ — матрица эмбеддингов айтемов
- d — размерность скрытого пространства (обычно 32–128)

Суть — представление пользователей и айтемов в общем пространстве, где скалярное произведение векторов uᵤ и vᵢ приближает интерес пользователя к айтему:

    ŷᵤᵢ = ⟨uᵤ, vᵢ⟩

**Отличия от классической коллаборативной фильтрации:**
- CF (user-based/item-based) не использует обучаемые эмбеддинги, а опирается на эвристические меры (например, cosine similarity).
- MF масштабируется лучше и работает в случае data sparsity.

---

## 12. Как MF позволяет избежать повторов в топ-N?

Факторизационные модели (например, ALS или BPR) строят эмбеддинги, отражающие интересы пользователя, и ранжируют все айтемы, включая новые и неинтерактированные. Айтемы, с которыми уже были взаимодействия, можно исключить из рекомендаций после ранжирования (пост-фильтрация).

Причина разнообразия:
- Обучение происходит на положительных и отрицательных взаимодействиях.
- Повтор взаимодействий не влияет на итоговую рекомендацию — модель учится отличать интересные от неинтересных айтемов.
- Итоговая top-N выдача — это "самые близкие" айтемы в латентном пространстве, которые ещё не были просмотрены.

---

## 13. Способы разбиения данных для оффлайн-оценки

| Метод         | Описание |
|---------------|----------|
| **Random Split** | Случайное деление взаимодействий на train/test |
| **User Split**   | Деление по пользователям |
| **Time-based split** | Использует временные метки, обучаемся на прошлом, тестируем на будущем |
| **Leave-one-out** | Для каждого пользователя последняя интеракция в test, остальные — в train |

**Наиболее валидный:** Time-based hold-out или Leave-one-out, так как имитируют реалистичный сценарий рекомендаций.

---

## 14. Что такое leave-one-out разбиение?

Leave-One-Out (LOO) — это стратегия, при которой:
- Для каждого пользователя берется **последнее** взаимодействие как test.
- Остальные — обучающая выборка.

Используется часто в implicit-сценариях.

Преимущества:
- Эффективно эмулирует предсказание "следующего действия".
- Подходит для top-N задач.

---

## 15. Как работает двухуровневая архитектура рекомендательной системы?

Двухуровневая (two-stage) архитектура включает два этапа:

1. **Retrieval (candidate generation)**:
   - Быстрое получение ~100–1000 кандидатов.
   - Используются модели: ALS, LightGCN, item2vec, KNN.
   - Оценка: простая (dot product, similarity).

2. **Ranking**:
   - Точный пересчет скорингов для кандидатов.
   - Используются ML-модели: GBM, DNN, DSSM.
   - Учитываются дополнительные фичи: контекст, временные признаки, device, session info и т.п.

Преимущества:
- Комбинирует масштаб и точность.
- Экономит ресурсы, так как сложная модель не применяется ко всем айтемам.

---

## 16. Можно ли использовать градиентный бустинг для ранжирования? Преимущества перед нейросетями

Да, градиентный бустинг (например, LightGBM, XGBoost) часто используется для задачи ранжирования.

### Преимущества бустинга:
- Не требует масштабирования признаков.
- Эффективно работает на табличных данных (features из логов, профиля, контекста).
- Устойчив к шумам, хорошо работает с категориальными фичами (с энкодингом).
- Быстро обучается и легко дебажится.
- Поддерживает различные ранжирующие loss'ы (rank:pairwise, rank:ndcg и т.п.).

### Недостатки:
- Хуже захватывает сложные зависимости, чем нейросети.
- Требует ручного инжиниринга признаков.
- Не масштабируется на миллионы пользователей/айтемов так же легко, как light-версии нейросетей.

Используется как второй уровень в two-stage системах.

---

## 17. Когда стоит (не) рекомендовать уже взаимодействованные айтемы?

### Когда не стоит рекомендовать:
- В случае one-time interaction (например, покупка билета, регистрация).
- Когда цель — новизна, расширение интересов.
- Если есть ограничения бизнеса (нельзя второй раз купить, например, подписку).

### Когда можно оставить:
- В сценариях повторных покупок (фрукты, бытовая химия).
- Если взаимодействие неполное (например, добавлено в корзину — но не куплено).
- В случае коротких сессий, где пользователь может забыть, что уже видел.

**Вывод:** всё зависит от задачи — можно исключать айтемы постфактум из рекомендаций, если необходимо.

---

## 18. Что такое гибридная рекомендательная система?

Гибридная система — это комбинация нескольких подходов (например, CF, контентный, knowledge-based и др.), чтобы:
- Улучшить покрытие и качество.
- Снизить проблемы холодного старта.
- Повысить устойчивость к ошибкам одного из методов.

### Основные типы гибридизации:
- **Weighted** — усреднение скорингов разных моделей.
- **Switching** — выбор модели в зависимости от условий (см. вопрос 30).
- **Mixed** — объединение результатов.
- **Cascade** — одна модель отбирает кандидатов, другая ранжирует.
- **Feature-level** — признаки из одной модели подаются в другую.

---

## 19. Какие рекомендательные подходы не зависят от домена?

Подходы, которые не требуют специфических знаний о предметной области:

- **Collaborative filtering** (user/item-based) — работает на взаимодействиях.
- **Matrix factorization** — только user/item ID.
- **Graph-based методы** (LightGCN, random walks) — используют структуру, но не контент.
- **Sequence-based** (например, SASRec) — основаны на последовательностях.

Все эти методы применимы в любом домене при наличии данных о взаимодействии.

---

## 20. Что такое popular bias?

Popular bias — смещение модели в сторону популярных айтемов.

### Причины:
- Частые взаимодействия с популярными товарами => модель переобучается на них.
- Метрики вроде Recall@k могут поощрять это поведение.

### Последствия:
- Потеря разнообразия и новизны.
- Рекомендации становятся однообразными.
- Хвостовая часть каталога игнорируется.

### Способы борьбы:
- Downsampling популярных айтемов.
- Использование diversity-aware метрик.
- Взвешивание при обучении (inverse popularity).

---

## 21. Что такое проблема холодного старта? Как её решать?

**Проблема холодного старта** возникает, когда:
- В системе появляются **новые пользователи** без истории.
- Или добавлены **новые айтемы**, по которым нет взаимодействий.

### Решения:
- **Для новых пользователей**:
  - Использовать демографические и контекстные фичи.
  - Предложить опрос (onboarding).
  - Content-based рекомендации (по интересам).

- **Для новых айтемов**:
  - Использовать контентные признаки (описание, категории).
  - Использовать мета-информацию (цена, бренд).
  - Knowledge graph (например, item2vec от соседей по графу).

- **Модели**:
  - LightFM — сочетает CF и контент.
  - DSSM — объединяет эмбеддинги фичей и взаимодействий.
  - Zero-shot learning, meta-learning для cold start.

---

## 22. Метрики novelty, diversity, coverage, serendipity

| Метрика       | Что измеряет                  | Пример формулы/идеи |
|---------------|-------------------------------|----------------------|
| **Novelty**   | Насколько рекомендации "новые" для пользователя | Популярность айтемов в выдаче |
| **Diversity** | Разнообразие внутри рекомендаций | Среднее расстояние между айтемами |
| **Coverage**  | Доля каталога, охваченная рекомендациями | |RecItems| / |AllItems| |
| **Serendipity** | Удивительность и польза одновременно | Разность между ожидаемым и полученным с положительным фидбеком |

Часто считаются вместе с точностью. Можно поощрять diversity и novelty через loss или re-ranking.

---

## 23. Что такое проблема feedback loop?

Feedback loop — это замкнутый цикл, при котором:
- Система рекомендует то, что пользователь уже и так видит.
- Пользователь кликает — модель усиливает уверенность.
- Новые/редкие айтемы не попадают в рекомендации.

**Итог:** система становится узконаправленной и ухудшает качество рекомендаций в долгосрочной перспективе.

### Решения:
- Exploration (рандомизация, epsilon-greedy).
- Моделирование non-exposure.
- Контроль diversity/novelty.
- A/B тесты для введения нового контента.

---

## 24. Что такое проблема информационного пузыря (information bubble)?

**Information bubble** = персонализация приводит к изоляции.

### Причина:
- Модель "узнает" интересы пользователя и начинает рекомендовать только релевантные вещи.
- Это ограничивает кругозор, снижает novelty.

### Примеры:
- В соцсетях: пользователь видит только посты, подтверждающие его мнение.
- В рекомендациях — отсутствие новых категорий товаров.

**Решения**:
- Добавлять diversity и serendipity.
- Ротация категории.
- Смешанные рекомендации (explore + exploit).

---

## 25. В чём разница между оффлайн и онлайн метриками?

| Тип метрики   | Описание |
|---------------|----------|
| **Оффлайн**   | Считаются на подготовленных разбиениях (Recall@k, NDCG@k, Precision). Быстро и дёшево. |
| **Онлайн**    | Измеряются в проде: CTR, конверсии, удержание. Показывают реальное поведение. |

### Почему они могут расходиться:
- Оффлайн метрики не учитывают bias (позиции, UI).
- Пользователи могут реагировать не на "лучший скор", а на оформление, контекст, момент.

**Вывод:** оффлайн = быстрая проверка; онлайн — финальное подтверждение гипотезы.

---

## 26–30. Обработка доступности, интерпретируемость, сезонность и гибридность

### 26. Почему не все айтемы могут быть доступны пользователю?

Рекомендательная система не всегда может рекомендовать все айтемы из каталога:

- **Физические ограничения**: товар закончился, нет в наличии, снят с продажи.
- **Юридические ограничения**: ограничения по региону, возрасту, лицензии.
- **Бизнес-ограничения**: исключения по бренду, фильтры платформы.
- **Пользовательские фильтры**: пользователь уже купил/лайкнул айтем или скрыл его.

➡️ В продакшене важно фильтровать недоступные айтемы ДО ранжирования или учитывать это в самой модели.

---

### 27. Что такое монотонные ограничения?

**Монотонные ограничения (monotonic constraints)** — это требования, что с увеличением значения признака модель должна увеличивать или уменьшать результат предсказания строго в одном направлении.

#### Пример:
Если увеличивается `user_rating`, то модель должна увеличивать предсказанную вероятность покупки.

#### Где применяются:
- В LightGBM, CatBoost и других GBDT-моделях:
  ```python
  lgb.train(params, train_set, ..., params={'monotone_constraints': [1, -1, 0]})
  ```

➡️ Они повышают интерпретируемость и стабильность, особенно в задачах с бизнес-ограничениями.

---

### 28. Как интерпретировать рекомендации с помощью SHAP-values?

**SHAP (SHapley Additive Explanations)** объясняет вклад каждого признака в предсказание модели.

#### Как работает:
- Оценивает, насколько каждый признак повлиял на рекомендацию (score).
- Строится на базе идей кооперативной теории игр (Shapley values).

#### Пример использования:
```python
import shap
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_val)
shap.summary_plot(shap_values, X_val)
```

➡️ Особенно полезен для:
- Поддержки доверия пользователя.
- Отладки модели.
- Соответствия требованиям прозрачности (например, GDPR).

---

### 29. Может ли модель второго уровня учитывать сезонность и как?

Да, модель второго уровня (ранкер) может учитывать сезонность через:

#### Временные признаки:
- `hour`, `dayofweek`, `month`, `is_weekend`, `is_holiday`
- Кол-во взаимодействий за последние N дней
- Time-since-last-interaction

#### Представление:
- One-hot кодирование
- Date embeddings (в DL)
- Перекрёстные признаки: `user × day`, `category × hour`

➡️ Также можно учитывать сезонность на уровне фильтрации айтемов (например, летом — пляжные товары).

---

### 30. Что такое switching в гибридных рекомендательных системах?

**Switching** — это подход, при котором выбор рекомендательной модели зависит от ситуации.

#### Пример логики:
```text
if user is new:
    use content-based filtering
elif item is new:
    use popularity-based recommendation
else:
    use collaborative filtering
```

#### Преимущества:
- Высокая адаптивность.
- Покрытие разных cold-start сценариев.

#### Недостатки:
- Требует качественной логики переключения.
- Возможны граничные ошибки (jump behavior).

➡️ Switching — простой, но эффективный способ комбинировать сильные стороны разных подходов.

---

### 31. Как работает implicit ALS и как его расширить?

#### Implicit ALS (Alternating Least Squares):
- Матричное разложение для неявных (implicit) данных
- Использует взвешенную функцию ошибки:

\[
\min_{X,Y} \sum_{u,i} c_{ui} (p_{ui} - x_u^T y_i)^2 + \lambda (\|x_u\|^2 + \|y_i\|^2)
\]
где:
- \( p_{ui} = 1 \) если есть взаимодействие, иначе 0
- \( c_{ui} = 1 + \alpha \cdot r_{ui} \) — confidence

#### Достоинства:
- Быстрое обучение (особенно с CPU/parallel)
- Устойчив к sparsity

#### Недостатки:
- Нет последовательности/контекста
- Трудно учитывать признаки

#### Как добавить признаки:
- Слияние внешних эмбеддингов в \( X \) и \( Y \)
- Factorization Machines
- Feature-aware sampling и LightFM

#### Как учесть время:
- Сэмплирование по decay-функции
- Матрицы по временам (утро, вечер)
- Взвешивание интеракций по давности

#### Объяснение:
- Объяснение в ALS возможно через похожесть: "Потому что похож на то, что вы смотрели"
- Можно интерпретировать через близость эмбеддингов

---

### 32. Как работает userKNN/itemKNN? Достоинства и недостатки

#### itemKNN:
- Рекомендации строятся на похожих айтемах:
  \[
  \hat{r}_{ui} = \sum_{j \in N(i)} \text{sim}(i, j) \cdot r_{uj}
  \]
  Где \( N(i) \) — k ближайших айтемов к \( i \)

#### userKNN:
- Рекомендации на основе похожих пользователей:
  \[
  \hat{r}_{ui} = \sum_{v \in N(u)} \text{sim}(u, v) \cdot r_{vi}
  \]

#### Метрики похожести:
- Cosine, Pearson, Jaccard

#### Плюсы:
- Простота, интерпретируемость
- Нет обучения — "memory-based"

#### Минусы:
- Медленно при большом числе пользователей/айтемов
- Плохо масштабируется

---

### 33. Как устроена модель EASE и чем отличается от SLIM?

#### EASE (Embarrassingly Shallow AutoEncoder):
- Линейная модель для рекомендаций на основе регрессии:
  \[
  \hat{r}_u = X_u \cdot B
  \]
  где \( B \) — матрица параметров, решается как:
  \[
  B = (X^T X + \lambda I)^{-1} X^T X
  \]

- Симметричность и регуляризация делают EASE очень эффективной

#### SLIM (Sparse Linear Methods):
- То же самое, но с L1-регуляризацией:
  \[
  \min_B \|X - XB\|^2 + \lambda_1 \|B\|_1 + \lambda_2 \|B\|_2
  \]
- Медленнее, но даёт разреженные веса

#### Отличия:

| Метод | Регуляризация | Быстрота | Интерпретируемость |
|-------|----------------|-----------|--------------------|
| EASE  | L2             | Очень быстрая | Да               |
| SLIM  | L1 + L2        | Медленная     | Да               |

---

### 34. Как работает LightFM? Достоинства и недостатки

**LightFM** — факторизационная модель, объединяющая CF и контентные признаки.

\[
\hat{r}_{ui} = \langle x_u, y_i \rangle
\]
где:
- \( x_u \) = эмбеддинг пользователя (в т.ч. от признаков)
- \( y_i \) = эмбеддинг айтема

#### Особенности:
- Использует признаки (теги, категории)
- Поддерживает разные loss: BPR, WARP, logistic

#### Плюсы:
- Подходит для cold start
- Быстрая и гибкая
- Поддержка scikit-learn стиля

#### Минусы:
- Ограничена по масштабируемости
- Нет учёта последовательности

---

### 35. Как работает SASRec? Достоинства и недостатки

**SASRec (Self-Attentive Sequential Recommendation)** — последовательная модель на основе Transformer.

#### Архитектура:
- Вход: последовательность айтемов \([i_1, i_2, ..., i_t]\)
- Каждое \( i_t \) проходит через:
  - эмбеддинг
  - позиционный эмбеддинг
  - self-attention блоки

\[
\hat{r}_{ui} = f_{\text{attn}}(i_1, ..., i_t, i)
\]

#### Плюсы:
- Учитывает порядок и дистанцию
- Обучается end-to-end
- Подходит для next-item prediction

#### Минусы:
- Тяжёлый при длинных последовательностях
- Неустойчив к sparsity
- Требует GPU

---

### 36. Как работает BERT4Rec? Достоинства и недостатки

**BERT4Rec** — последовательная модель, основанная на bidirectional Transformer (BERT), обучается с маскированием.

#### Отличие от SASRec:
- SASRec — унидирекционный (предсказывает следующее)
- BERT4Rec — бидирекционный (восстанавливает маски)

#### Обучение:
- Маскируется часть айтемов
- Цель: восстановить их с помощью внимания

\[
\mathcal{L} = \sum_{i \in \text{masked}} -\log P(i | \text{context})
\]

#### Плюсы:
- Учит глобальный контекст
- Работает как автокодировщик

#### Минусы:
- Сложнее в инференсе
- Тяжелее, чем SASRec
- Не может использоваться напрямую для autoregressive задач

---

### 37. Отличия между BERT4Rec и SASRec

| Характеристика        | SASRec                          | BERT4Rec                          |
|------------------------|----------------------------------|------------------------------------|
| Направленность        | Упорядоченный (left-to-right)   | Бидирекциональный                 |
| Обучение              | Next item prediction             | Masked item prediction            |
| Loss                  | BPR / Cross-Entropy              | MLM (Masked LM)                  |
| Скорость инференса    | Быстрее                          | Медленнее                         |
| Учёт порядка          | Есть                             | Есть, но без авто-регрессии       |

---

### 38. Как работает LightGCN? Достоинства и недостатки

**LightGCN** — упрощённая версия GCN для коллаборативной фильтрации.

#### Основная идея:
- Представить интеракции как граф \( G = (U \cup I, E) \)
- Эмбеддинги обновляются по соседям:

\[
e_u^{(k+1)} = \sum_{i \in \mathcal{N}(u)} \frac{1}{\sqrt{|\mathcal{N}(u)||\mathcal{N}(i)|}} e_i^{(k)}
\]

- Итоговая эмбеддинговая сумма:
\[
e_u = \sum_{k=0}^K \alpha_k e_u^{(k)}
\]

#### Плюсы:
- Учитывает структуру графа
- Простая и масштабируемая

#### Минусы:
- Не учитывает время и контент
- Статичная архитектура (всё эмбеддинги фиксированы)
---

### 39. Как из обученного вариационного автоэнкодера получить рекомендации?

**VAE** (Variational AutoEncoder) используется для генерации скрытых представлений пользователя:
- Вход: бинарный вектор взаимодействий \( x_u \)
- Кодер: \(\mu_u, \sigma_u = f_{\text{enc}}(x_u)\)
- Сэмплируется латентный вектор: \( z_u \sim \mathcal{N}(\mu_u, \sigma_u^2) \)
- Декодер: предсказывает вероятность взаимодействия с каждым айтемом:
  \[
  \hat{r}_u = f_{\text{dec}}(z_u)
  \]

#### Получение рекомендаций:
1. На инференсе берём \(\mu_u\) как эмбеддинг
2. Считаем \(\hat{r}_u = f_{\text{dec}}(\mu_u)\)
3. Выбираем топ-N по \(\hat{r}_u\)

---

### 40. Как работает MultiVAE? Чем отличается от MultiDAE?

**MultiVAE** — вероятностная модель для рекомендаций, обучаемая с использованием регуляризации на латентное пространство.

\[
\mathcal{L} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - \beta \cdot \text{KL}(q(z|x) \| p(z))
\]

**MultiDAE** — тот же автоэнкодер, но без вероятностной составляющей:
- Нет sampling и KL-дивергенции
- Обучается просто как реконструкция

#### Сравнение:

| Характеристика  | MultiVAE                    | MultiDAE                    |
|------------------|------------------------------|------------------------------|
| Латентное пространство | Стохастическое (\( z \sim N(\mu, \sigma) \)) | Детерминированное |
| Регуляризация   | Да (KL)                      | Нет                         |
| Подходит для cold-start | Лучше                    | Хуже                        |

---

### 41. Как можно делать объяснения рекомендаций?

Способы объяснения:

#### 1. **Интринсивные (встроенные)**:
- KNN: "Потому что вы смотрели X, похожий на Y"
- Decision Trees: можно проследить путь
- GNN attention / веса эмбеддингов

#### 2. **Агностические (post-hoc)**:
- SHAP: вклад признаков
- LIME: локальная аппроксимация модели
- Attention weights (в SASRec/BERT4Rec)

#### 3. **Темпоральные**:
- Показывать прошлую последовательность, которая привела к выбору

---

### 42. Что такое uplift-рекомендации? Примеры моделей

**Uplift** — модель предсказывает **разницу эффекта от рекомендации**:
\[
\text{Uplift} = P(Y=1 | T=1, X) - P(Y=1 | T=0, X)
\]

Где:
- \(T=1\) — если был рекомендован айтем
- \(Y\) — целевое действие (клик, покупка)

#### Применения:
- Оценка эффекта показа
- Оптимизация показов (только если uplift положителен)

#### Модели:
- Uplift Random Forest
- Causal Forest
- Meta-learners (T-learner, X-learner)
- DeepUplift / GAN-based подходы

---

### 43. Примеры multi-task задач и подходящая архитектура

#### Примеры задач:
- Предсказать одновременно:
  - Клик (CTR)
  - Покупку (CVR)
  - Отток (churn)
  - Лайк + комментарий

#### Подходящие архитектуры:
- **Shared-bottom**: общие слои + task-specific heads
- **MMoE** (Multi-gate Mixture-of-Experts)
- **PLE** (Progressive Layered Extraction)

#### Зачем:
- Повышает сэмпловую эффективность
- Учит представления общего вида

---

### 44. Что такое кросс-доменные рекомендации?

**Cross-domain RS** — перенос предпочтений пользователя между разными предметными областями:
- Книги → фильмы
- Видео → e-commerce

#### Применения:
- Cold start
- Дополнительные сигналы интереса
- Повышение разнообразия

#### Методы:
- Совместное латентное пространство
- Mapping функций между доменами
- Мета-обучение

---

### 45. Чем операция свёртки в CNN отличается от графовой свёртки?

#### CNN:
- Применяется к регулярным структурам (изображения, текст)
- Ядро свёртки "скользит" по фиксированной сетке

\[
y_{i,j} = \sum_{m,n} x_{i+m, j+n} \cdot w_{m,n}
\]

#### GCN (Graph Conv):
- Применяется к неструктурированным графам
- Обновление происходит через соседей:

\[
h_v^{(k+1)} = \text{AGG}(\{h_u^{(k)} : u \in \mathcal{N}(v)\})
\]

#### Отличия:

| Свёртка         | CNN                               | GCN                             |
|------------------|------------------------------------|----------------------------------|
| Данные            | Регулярная решетка                | Граф                            |
| Окружение         | Фиксированное окно                | Гибкое множество соседей        |
| Агрегация         | Фиксированная (матрица весов)     | Функция: mean/sum/attention     |
---

### 46. Что такое model-agnostic и model-intrinsic подходы? Примеры

#### Model-agnostic (вне зависимости от модели):
- Работает как "чёрный ящик"
- Можно использовать с любой моделью
- Примеры:
  - **LIME**: аппроксимирует модель локально
  - **SHAP**: оценивает вклад признаков
  - **Permutation Feature Importance**

#### Model-intrinsic (встроенные в модель):
- Интерпретация идёт из структуры модели
- Примеры:
  - **Weights в логистической регрессии**
  - **Attention в Transformer**
  - **Feature split importance в деревьях**

| Подход         | Примеры         | Применимость      |
|----------------|------------------|--------------------|
| Agnostic       | SHAP, LIME       | Универсально       |
| Intrinsic      | Attention, веса  | Только для моделей |

---

### 47. Типы перекрытия данных в cross-domain рекомендациях

1. **User-overlap**: один пользователь есть в обоих доменах
2. **Item-overlap**: один и тот же айтем встречается в обоих
3. **Feature-overlap**: пересекаются признаки айтемов/юзеров
4. **No-overlap**: нет общего, нужен transfer learning

| Перекрытие    | Пример                       |
|----------------|-------------------------------|
| User           | Один и тот же email в Netflix и Spotify |
| Item           | Книга доступна и на Amazon, и в Lib.ru |
| Feature        | Айтемы имеют одинаковые жанры |
| None           | Разные домены, обучаем mapping |

---

### 48. Что такое граф знаний и как его использовать в рекомендациях?

**Граф знаний** — семантический граф, где узлы — сущности, рёбра — отношения.

Пример:
- Узлы: фильм, актёр, жанр
- Рёбра: "играл", "жанр", "режиссёр"

#### Использование в RS:
1. **Feature enrichment**: добавление признаков к айтемам
2. **Path-based RS**: используем пути в графе как признаки
3. **GNN-based RS**: обучение на графе знаний
4. **KG-Aware MF**: объединим с латентной факторизацией

#### Пример моделей:
- **KGCN** (Knowledge Graph Convolutional Network)
- **RippleNet** (спред интересов через граф)

---

### 49. Бейзлайны для next basket prediction (NBP). Как считать популярность?

#### Бейзлайны:
- **Most popular**: топ частых айтемов
- **Repeat model**: повтор предыдущих покупок
- **Association rules**: "если A, то B"
- **Item2Vec / Prod2Vec**: эмбеддинги айтемов
- **FPMC**, **GRU4Rec**, **SASRec**

#### Подсчёт популярности:
\[
\text{Popularity}(i) = \frac{\text{count}(i)}{\sum_j \text{count}(j)}
\]

Может считаться по:
- количеству покупок
- уникальным пользователям
- недавним взаимодействиям

---

### 50. Отличия между batch и real-time рекомендациями. Когда нужен online?

#### Batch RS:
- Обновление рекомендаций раз в N часов
- Используется precomputed модели (ALS, LightGCN)
- Подходит для стабильных фидов

#### Real-time RS:
- Учитывает последние действия
- Использует session-based модели, faiss + nearest neighbors

#### Отличия:

| Характеристика     | Batch                        | Real-time                     |
|---------------------|-------------------------------|-------------------------------|
| Обновление         | Периодическое                  | Немедленное                   |
| Модели              | Pretrained                    | Online / lightweight          |
| Примеры             | ALS, LightGCN                 | GRU4Rec, Faiss + Recency      |

#### Когда делать online:
- В e-commerce, где сессия — главный источник интента
- Когда CTR сильно зависит от последнего действия
- При A/B тестировании с быстрым фидбеком

---

### 51. Что такое контент? Что такое контекст? Примеры

- **Контент (content)**: описание айтема или пользователя
  - Примеры: жанр фильма, цена, описание, эмбеддинг из текста

- **Контекст (context)**: внешние условия взаимодействия
  - Примеры: время суток, локация, устройство, сессия

| Параметр | Примеры                       |
|----------|-------------------------------|
| Контент  | возраст юзера, тег айтема     |
| Контекст | утро, Москва, с мобильного    |

---

### 52. Как работает DSSM? Какой лосс используется?

**DSSM (Deep Structured Semantic Model)** — двухбашенная нейросеть для матчинга (user, item):
- Одна башня обрабатывает пользователя, другая — айтем
- Выход: эмбеддинги \( u, v \)
- Сходство: cosine similarity или dot product:
  \[
  \hat{y}_{ui} = \frac{u \cdot v}{\|u\| \cdot \|v\|}
  \]

#### Loss:
- Cross-entropy (softmax over negatives)
- Triplet loss
- InfoNCE:
  \[
  \mathcal{L} = -\log \frac{\exp(\text{sim}(u, v^+))}{\sum_{j} \exp(\text{sim}(u, v_j))}
  \]

Применяется в:
- Поиске (query–document)
- Рекомендациях (user–item)

---

### 53. В чём идея beeFormer?

**beeFormer** — это архитектура рекомендательной модели, вдохновлённая поведением пчёл. Ключевая идея: агрегировать информацию от похожих пользователей/айтемов и направлять внимание как в self-attention, так и в cross-user/item attention.

#### Основные черты:
- Использует механизм **swarm attention**
- Адаптивно ищет релевантные элементы во всём пространстве
- Эффективен в ситуации с длинными последовательностями

#### Применения:
- session-based RS
- long-range dependencies

---

### 54. Зачем использовать последовательность?

Учет последовательности позволяет:
- Учитывать **порядок интересов** пользователя
- Захватывать **динамику предпочтений**
- Улучшать **контекстуальную релевантность**

#### Примеры:
- SASRec: self-attention поверх последовательности
- GRU4Rec: RNN на истории взаимодействий

Последовательность особенно важна в e-commerce и видео-рекомендациях, где действия пользователя идут цепочкой.

---

### 55. Как работает RNN?

**RNN (Recurrent Neural Network)** — нейросеть, где выход зависит от текущего входа и предыдущего состояния:
\[
h_t = \tanh(W x_t + U h_{t-1} + b)
\]

- \(h_t\): скрытое состояние
- Запоминает информацию о последовательности
- Проблема: **затухающие градиенты** → плохо работает на длинных последовательностях

---

### 56. В чём идея LSTM/GRU? Какую проблему они решают?

LSTM и GRU — разновидности RNN, разработанные для борьбы с **vanishing gradients** и запоминания долгосрочных зависимостей.

#### LSTM:
- Использует **ячейку памяти** и **3 гейта** (input, forget, output)
- Позволяет "решать", какую информацию сохранить/забыть

\[
c_t = f_t \cdot c_{t-1} + i_t \cdot \tilde{c}_t
\]

#### GRU:
- Более компактная архитектура
- Объединяет input и forget гейты

\[
h_t = (1 - z_t) \cdot h_{t-1} + z_t \cdot \tilde{h}_t
\]

---

### 57. Что такое fusion? В чём идея? Зачем это делать? Какие бывают типы fusion?

**Fusion** — объединение разных источников информации в модели (например, текст, изображение, числа).

#### Зачем:
- Использовать больше признаков
- Улучшить обобщающую способность
- Поддержать мультимодальность

#### Типы fusion:
1. **Early fusion** — объединение признаков на входе
2. **Late fusion** — объединение результатов разных моделей
3. **Hybrid fusion** — комбинация и того, и другого

Пример: объединить эмбеддинг текста описания и эмбеддинг изображения товара

---

### 58. Как обрабатывать категориальные признаки для подачи в нейросети (мультимодальные рекомендации)?

#### Основные способы:
1. **Embeddings**: каждому уникальному значению соответствует вектор
   \[
   \text{Emb}(x_{\text{cat}}) \in \mathbb{R}^d
   \]

2. **One-hot**: редко используется в DL из-за разреженности
3. **Target encoding**: для простых моделей, не рекомендуется в DL

#### Важно:
- Embedding dim ≈ \(d = \min(50, \text{size}^{0.25})\)
- Не забывать про rare-categories handling и padding

---

### 59. Как обрабатывать вещественные признаки для подачи в нейросети (мультимодальные рекомендации)?

#### Способы:
1. **Нормализация**:
   - min-max scaling
   - z-score (стандартизация)
   - log(x+1) — для перекошенных распределений

2. **Bucketization**:
   - Разбиение на бины → one-hot или embedding

3. **BatchNorm / LayerNorm**:
   - Улучшает стабильность обучения

#### Пример:
- Цена товара → log1p + нормализация + linear projection

---
